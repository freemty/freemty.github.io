<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sum Tower</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://freemty.github.io/"/>
  <updated>2019-11-30T16:11:36.358Z</updated>
  <id>http://freemty.github.io/</id>
  
  <author>
    <name>Sum Young</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>「Paper-Reading」SuperAE</title>
    <link href="http://freemty.github.io/2019/11/30/superAE/"/>
    <id>http://freemty.github.io/2019/11/30/superAE/</id>
    <published>2019-11-30T15:29:35.000Z</published>
    <updated>2019-11-30T16:11:36.358Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1805.04869v1.pdf" target="_blank" rel="noopener">Original-version Link</a></p><h3 id="abstrct">Abstrct</h3><p>现今主流的摘要生成都是基于seq2seq，但事实上用于训练的文本大都过于冗杂（即使LCSTS也存在这个问题），导致在在encode时很难真正的“习得”语义（semantic），而reference summary大都短且语义明确。文中提出的模型「SuperAE」正是利用了这一点，在encode时引入了监督。取得了，很好的结果。</p><h3 id="introduction">Introduction</h3><p>由于RNN结构的特性，不管作何变种和优化（LSTM，GRU），都难以避免梯度爆炸和消失，因此可以说编码长文本时语义的遗失是一种必然。而对于短文本的编码则可以很好的理解语义。根据这个思路，可以在编码时增加对summary的编码，用它来监督encoder对原文的的“理解”情况。</p><h3 id="proposed-model">Proposed Model</h3><h4 id="supervision-with-autoencoder">Supervision with Autoencoder</h4><p>传统的seq2seq在这就不多赘述，encode层还是主流的双层LSTM，在训练时，加入了新的摘要编码器，输出为<span class="math inline">\(z_s\)</span>,引入了新的损失项(<span class="math inline">\(\lambda\)</span>有经验值0.3作为初始值） <span class="math display">\[ L_s =\frac{\lambda}{N_h}d(z_t,z_s)\]</span> 其中 <span class="math display">\[d(z_t,z_s) = ||z_t - z_s||_2\]</span></p><p>显而易见此监督（supervisor）项用以描述二者输出的相似度。按我从直觉上的理解，监督项，可以很好的防止模型不被比较晦涩或者说质量较差的摘要样例带偏。</p><figure><img src="/2019/11/30/superAE/ae_graph.png" alt="model"><figcaption>model</figcaption></figure><h4 id="adversarial-learning">Adversarial Learning</h4><p>上一节添加了用于监督的新损失项，因此就存在了新的超参数<span class="math inline">\(\lambda\)</span>用来控制监督的力度。显而易见，训练时，如果摘要和原文的语义相关性很高，那么监督的力度应该较高，反之，如果摘要太草了(QAQ),就应该适当降低监督的惩罚力度。因此，如果训练时的惩罚力度是动态的，训练的效果当然会更好。所以我们需要一种技巧来判别这组文本和摘要的相关性，是否需要“加大力度”。</p><p>到这里，就该对抗学习（adversarial learning）出场了。本文先验的把seq2seq里的输出看作虚假表示（“fake”representation），autoencoder的输出看作标准表示（“gold” representation）。对此，在训练中引入了discriminator（判别器？歧视器？），用来分辨输出到底是“gold”还是“fake”。</p><p>从数学上理解，这是判别器的目标函数 <span class="math display">\[L_D(\theta_D) = -logP_{\theta_D}(y  =1|z_t)-logP_{\theta_D}(y = 0|z_s)\]</span> 这是监督学习的目标函数 <span class="math display">\[L_G(\theta_E) = -logP_{\theta_D}(y  =0|z_t)-logP_{\theta_D}(y = 1|z_s)\]</span> 从直觉上理解，监督学习有着使两编码器的输出语义无限接近的动机，而判别器有尽力分别二者的动机，二者都存于损失函数中，如果辨别器可以区分二者，<span class="math inline">\(\lambda\)</span>减小，减轻监督力度，反之<span class="math inline">\(\lambda\)</span>增加，加大力度。</p><p>这里看的有点迷，把原文po上来把</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">the supervision, which minimizes the dis-tance of the representations and makes them sim-ilar, tries to prevent the discriminator from mak-ing correct predictions.</span></pre></td></tr></table></figure><h3 id="loss-function-and-training">Loss Function and Training</h3><p>loss-function共由三部分组成，第一部分是原本seq2seq decoder和autoencoder均经过decod后输出的交叉熵的和，第二部分是上文第一节监督项的损失，第三部分是上文第二节判别器的损失。</p><p><span class="math display">\[L_1 = L_{seq2seq} + L_{AE} + L_s + L_D + L_G\]</span></p><h3 id="results">Results</h3><p><img src="/2019/11/30/superAE/result.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1805.04869v1.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Original-version Link&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;abstrct&quot;&gt;Abstrct&lt;/h
      
    
    </summary>
    
    
    
      <category term="NLP" scheme="http://freemty.github.io/tags/NLP/"/>
    
      <category term="paper reading" scheme="http://freemty.github.io/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://freemty.github.io/2019/11/30/hello-world/"/>
    <id>http://freemty.github.io/2019/11/30/hello-world/</id>
    <published>2019-11-30T13:18:36.680Z</published>
    <updated>2019-11-30T13:18:36.680Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo server</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo generate</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
