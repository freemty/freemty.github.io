<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sum Stack</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://freemty.github.io/"/>
  <updated>2022-02-08T15:36:49.735Z</updated>
  <id>http://freemty.github.io/</id>
  
  <author>
    <name>Sum Young</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>「Paper-Reading」YOLO Family</title>
    <link href="http://freemty.github.io/2021/04/30/YOLO/"/>
    <id>http://freemty.github.io/2021/04/30/YOLO/</id>
    <published>2021-04-30T15:29:35.000Z</published>
    <updated>2022-02-08T15:36:49.735Z</updated>
    
    <content type="html"><![CDATA[<p>YOLO,You Only Look Once!</p><a id="more"></a><h3 id="section"></h3><p>站在2021年这个时间点上,CV领域目标检测的模型已经百花齐放,各个版本的YOLO已经成为了几乎是OR任务的默认选项.但尽管能跑通训练,对我而言,YOLO的本质还只是一个会自动找人的模型,其内在的原理仍然是黑盒.</p><p><a href="https://arxiv.org/pdf/1506.02640.pdf" target="_blank" rel="noopener">YOLOV1</a></p><h3 id="整体结构">整体结构</h3><p>YOLO V1 中有24个和两个线型层</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;YOLO,You Only Look Once!&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="http://freemty.github.io/tags/CV/"/>
    
      <category term="paper reading" scheme="http://freemty.github.io/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>Words about ancient history</title>
    <link href="http://freemty.github.io/2020/06/02/interestingwords/"/>
    <id>http://freemty.github.io/2020/06/02/interestingwords/</id>
    <published>2020-06-02T14:19:18.000Z</published>
    <updated>2020-06-02T14:53:16.173Z</updated>
    
    <content type="html"><![CDATA[<p>最近痴迷词源，打算开一个说文解字环节</p><a id="more"></a><h5 id="cicerone博物馆导游"><code>cicerone</code>  (博物馆)导游</h5><blockquote><p>cicerone A guide, especially one who takes tourists to museums, monuments, or architectural sites and explains what is being seen.</p></blockquote><p>  西塞罗（Cicero），熟悉罗马历史的人自然不会陌生，著名的雄辩家、政治家。他在行政与辩论时总是风度翩翩且也满腹经纶，因而我们会称那些博物馆的的为<code>cicerone</code>(和西塞罗一样懂的人)。<br></p><h5 id="stoic坚韧的苦修的"><code>stoic</code>  坚韧的、苦修的</h5><blockquote><p>The Stoics were members of a philosophical movement that first appeared in ancient Greece and lasted well into the Roman era. Stoicism taught that humans should seek to free themselves from joy, grief, and passions of all kinds in order to attain wisdom; its teachings thus have much in common with Buddhism.</p></blockquote><p>  <code>stoic</code>源于斯多葛主义（Stoicism），斯多葛学派认为我们要持戒，远离享乐以追求有德行的生活。最著名的斯多葛主义者有西塞罗（Cirero)、罗马皇帝马可·奥勒留（Marcus Aurelius）</p><blockquote><p>e.g. She bore the pain of her broken leg with such stoic patience that most of us had no idea she was suffering.</p></blockquote><h5 id="hedonism-享乐主义"><code>hedonism</code> 享乐主义</h5><blockquote><p>An attitude or way of life based on the idea that pleasure or happiness should be the chief goal.</p></blockquote><p>  <code>hedonism</code>的词源是希腊语的&quot;ἡδονή（hēdonē）&quot;（享乐）加上后缀&quot;ισμός（ismos）&quot;（主义）<br> 说到<code>hedonism</code> 就不得不提伊壁鸠鲁主义（Epicureanism）。希腊哲学家伊比鸠鲁认为，人生追根究底不过是为了享受快乐。不过，这里的快乐并不是指性爱跟毒品，而是没有痛苦的。他认为快乐有两种，一种是短暂的，另一种是持久的。短暂的快乐是从满足需求而来，口渴的人喝到水会感觉到快乐，疲倦的人躺下休息也会感到快乐。除了这种短暂的快乐之外，还有一种持久的快乐，而这才会带来真正幸福的生活。这种持久的快乐，指的是没有痛苦，也没有强烈匮乏的状态。<br></p><blockquote><p>e.g. In her new spirit of hedonism, she went out for a massage, picked up champagne and chocolate truffles, and made a date that evening with an old boyfriend.</p></blockquote><h5 id="delphic模糊的暧昧的"><code>delphic</code>  模糊的、暧昧的</h5><blockquote><p>Unclear, ambiguous, or confusing.</p></blockquote><p>  德尔菲（Delphi）是希腊阿波罗神庙的所在地，祭司会在这里接受神喻以占卜吉凶。以其神喻的晦涩暧昧而有的这个词。<br>  神喻这和算命一个道理，总是给出的都是看似富有哲理，实则模棱两可的答案（这也是”神“维持一种卡里斯玛的必要手段）。吕底亚（Lydia）国王，曾来问询波斯是否会攻打自己的国家，神喻说“会有一个庞大的帝国覆灭”，国王自然以为所指的是波斯，谁知最终覆灭的却是他自己的帝国。<br></p><blockquote><p>​ e.g. All she could get from the strange old woman were a few delphic comments that left her more confused than ever about the missing documents.</p></blockquote><h5 id="thespian演员"><code>thespian</code>  演员</h5><blockquote><p>actor</p></blockquote><p>  公元前六世纪的泰斯庇斯（Thespis）是古希腊“悲剧”（Tragedy）的开创者。最初，古希腊的戏剧都是歌队的合唱而他第一次将酒神祭典上的合唱改写成了对话剧本，将表演引入了戏剧，并且也是由他本人初次表演自己创作的悲剧剧本。<br>  自他以后希腊才有了真正意义上的戏剧，而他也第一位是真正意义上actor，也难怪人们会用<code>thespian</code>来指代演员。<br></p><blockquote><p>​ e.g. In summer the towns of New England welcome troupes of thespians dedicated to presenting plays of all kinds.</p></blockquote><h4 id="words-from-homeric">Words from Homeric</h4><h5 id="hector威吓的"><code>hector</code>  威吓的</h5><blockquote><p>To talk and behave towards someone in a loud and unpleasantly forceful way, especially in order to get them to act or think as you want</p></blockquote><p>  在历史上，赫克托耳（Hector）是特洛伊王子，帕里斯的哥哥。特洛伊第一勇士，被称为“特洛伊的城墙”，勇冠三军，为人正直，是古希腊传说中的的英雄形象，最终被阿克琉斯（Achilles）所杀。<br>  但在《伊利亚特》中，似乎荷马并不是很喜欢赫克托耳，赫克托尔被描写为嗜杀。英语中似乎继承了这种观点。<code>hector</code>有威吓，恃强凌弱，虚张声势的贬义.</p><blockquote><p>e.g. He would swagger around the apartment entrance with his friends and hector the terrified inhabitants going in and out.</p></blockquote><h5 id="stentorian大声的洪亮的"><code>stentorian</code>  大声的、洪亮的</h5><blockquote><p>Stentor, like Hector, was a warrior in the Iliad, but on the Greek side. His unusually powerful voice (Homer calls him “brazen-voiced”—that is, with a voice like a brass instrument) made him the natural choice for delivering announcements and proclamations to the assembled Greek army, in an era when there was no way of artificially increasing the volume of a voice.</p></blockquote><p>  斯藤托耳（Stentor）是特洛伊战争中联军的传令官，以其大嗓门而闻名<br></p><blockquote><p>e.g. Even without a microphone, his stentorian voice was clearly audible in the last rows of the auditorium.</p></blockquote><h5 id="nestor-睿智的长者"><code>nestor</code>   睿智的长者</h5><blockquote><p>Nestor was another character from the Iliad, the eldest of the Greek leaders in the Trojan War. A great warrior as a young man, he was now noted for his wisdom and his talkativeness, both of which increased as he aged.</p></blockquote><p>  涅斯托尔（Nestor）是皮洛斯国王涅琉斯的儿子，也是涅琉斯的12个儿子中唯一未被赫拉克勒斯杀死的幸存者。而在《伊利亚特》中，涅斯托尔是联军中一位睿智、长寿的领袖，常用自己的智慧与阅历来激励年轻的战士。<br>  在英语语境中，<code>nestor</code>指的是那种阅历丰富，能给出建议且不说教（爹味儿不重）的长者。</p><blockquote><p>e.g. He would swagger around the apartment entrance with his friends and hector the terrified inhabitants going in and out.</p></blockquote><h4 id="words-from-the-gods-of-athens">Words from the gods of Athens</h4><h5 id="dionysian-冲动的狂欢的"><code>Dionysian</code> 冲动的、狂欢的</h5><blockquote><p>Frenzied, delirious..</p></blockquote><p>  狄俄尼索斯（Dionysus），是希腊神话中的酒神与剧作之神。熟悉尼采对酒神精神肯定不会陌生。酒神有着极其丰富的精神意涵。在许多哲学与文学（尤其是尼采）表述中，酒神与日神被视作两种对立的精神。最浅显的讲，日神精神的核心是美的外观，是节制有序和理性，它指涉的是形式主义和古典主义、视觉艺术。而酒神精神更多是一种痛苦与狂喜快乐交织的状态，大都是非理性或需要借助极端体验来达成的，它指涉的是浪漫主义、音乐和表演艺术。<br>  酒神精神的来源是希腊的酒神祭，在酒神祭中，人们打破禁忌、放纵欲望，解除一切束缚，复归自然。酒神状态的迷狂，它对人生日常界线和规则的破坏，期间，包含着一种恍惚的成分，个人过去所经历的一切都淹没在其中了。是一种狂热、疯狂的快感、是人与人之间的界限消弥。<br></p><h5 id="apollonian-理性的和谐的"><code>Apollonian</code> 理性的、和谐的</h5><blockquote><p>Harmonious, ordered, rational, calm.</p></blockquote><p>  阿波罗（Apollo）作为日神。由于尼采对”日神精神“的强调，阿波罗作为酒神的反面，成为了理性、冷静、秩序的象征。还有一个同义词<code>bacchanalian</code>，同样是指酒神式的，不过词源是罗马的酒神 <br></p><blockquote><p>e.g. After a century of Romantic emotion, some composers adopted a more Apollonian style, producing clearly patterned pieces that avoided extremes of all kinds.</p></blockquote><h5 id="venereal-性病性交的"><code>venereal</code> 性病、性交的</h5><blockquote><p>Having to do with sexual intercourse or diseases transmitted by it.</p></blockquote><p>  维纳斯（Venus）是古罗马爱神的名字，在希腊神话中牠的名字是阿佛洛狄忒（Aphrodite）。有趣的是，爱神的希腊名字和罗马名字分别是金星（Venus）和星期五（Firday）的词源。<br></p><blockquote><p>e.g. In the 19th century syphilis especially was often fatal, and venereal diseases killed some of the greatest figures of the time.</p></blockquote><h5 id="mercurial-神速的不稳定的"><code>mercurial</code> 神速的、不稳定的</h5><blockquote><p>Having rapid and unpredictable changes of mood</p></blockquote><p>  罗马神墨丘利（Mercury）也就是我们熟知的赫尔墨斯（Hermes）是掌管旅行之神，他行走如飞，因而成为神速的代名词。而水星被罗马人命名为Mercury，也是因为它的移动快<br></p><blockquote><p>​ e.g. His mother's always mercurial temper became even more unpredictable, to the point where the slightest thing would trigger a violent fit.</p></blockquote><h5 id="jovial-愉悦"><code>jovial</code> 愉悦</h5><blockquote><p>Jolly, good-natured.</p></blockquote><p>  罗马神朱庇特（ Jupiter or Jove），就是众神之王宙斯（Zeus）。因为其地位高，罗马人也将他们已知的最大的行星木星命名为<code>Jupiter</code>。占星术从东方传到罗马帝国时，占星家宣称那些“生于木星下”的人注定要快乐大方，因而这也成了“愉悦”的代名词，这也也是<code>-joy</code>这个词根的来源。<br> 或许是英语受拉丁语影响更大的缘故，这些词源都是罗马神的名字而非希腊神话中的本名</p><blockquote><p>e.g. Their grandfather was as jovial and sociable as their grandmother was quiet and withdrawn</p></blockquote><h5 id="muse-沉思冥想"><code>muse</code> 沉思、冥想</h5><blockquote><p>A source of inspiration; a guiding spirit.</p></blockquote><p>  缪斯（The Muse），是希腊九位女神的总称，他们是音乐与艺术之神，她们喜欢歌手，所以会赐予她们灵感</p><blockquote><p>At 8:00 each morning he sat down at his desk and summoned his muse, and she almost always responded.</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近痴迷词源，打算开一个说文解字环节&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="English" scheme="http://freemty.github.io/tags/English/"/>
    
  </entry>
  
  <entry>
    <title>attention</title>
    <link href="http://freemty.github.io/2020/03/04/attention/"/>
    <id>http://freemty.github.io/2020/03/04/attention/</id>
    <published>2020-03-04T08:08:39.000Z</published>
    <updated>2022-02-08T14:11:57.203Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    <summary type="html">
    
      
      
        

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>隐马尔可夫模型</title>
    <link href="http://freemty.github.io/2020/02/27/HMM/"/>
    <id>http://freemty.github.io/2020/02/27/HMM/</id>
    <published>2020-02-27T10:20:50.000Z</published>
    <updated>2020-02-27T10:36:11.028Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要整理自shuhuai008大佬的<a href="https://space.bilibili.com/97068901" target="_blank" rel="noopener">白班推导</a>的版书和《统计学习方法》第九章HMM</p><a id="more"></a><h3 id="基本概念">基本概念</h3><p>HMM(隐马尔可夫模型)作为一种常见的序列建模的方法，</p><p>在隐马尔可夫模型中，我们对存在隐状态与观测值的</p><p>HMM中的参数为三元组<span class="math inline">\(\lambda = (\pi,A,B)\)</span> 其中<span class="math inline">\(A\)</span>为状态转移矩阵，</p><p><span class="math inline">\(I\)</span>为每一时刻的隐状态的集合，<span class="math inline">\(O\)</span>为每一时刻观测值的集合，即:</p><p><span class="math display">\[I = \{i_1,i_2,...,i_T\}, \; O =\{o_1,o_2,...o_T\}\]</span></p><p>HMM有两个重要的性质</p><p><strong>1.齐次Markov性</strong> 每一时刻的观测值仅仅依赖当前时刻的隐状态 <span class="math display">\[p(i_{t+1}|i_t,i_{t-1},\cdots,i_1,o_t,o_{t-1},\cdots,o_1)=p(i_{t+1}|i_t)\]</span></p><p><strong>2.观测独立性</strong>每一时刻的隐状态仅依赖于其前一时刻 <span class="math display">\[p(o_t|i_t,i_{t-1},\cdots,i_1,o_{t-1},\cdots,o_1)=p(o_t|i_t)\]</span> HMM的三个基本问题：</p><p>1.Evaluation：<span class="math inline">\(p(O|\lambda)\)</span>，Forward-Backward 算法</p><p>2.Learning：<span class="math inline">\(\lambda=\mathop{argmax}\limits_{\lambda}p(O|\lambda)\)</span>，Baum-Welch 算法</p><p>3.Decoding：<span class="math inline">\(I=\mathop{argmax}\limits_{I}p(I|O,\lambda)\)</span>，Vierbi 算法</p><p>预测问题：<span class="math inline">\(p(i_{t+1}|o_1,o_2,\cdots,o_t)\)</span> ​- 2.滤波问题：<span class="math inline">\(p(i_t|o_1,o_2,\cdots,o_t)\)</span></p><h3 id="evaluation问题">Evaluation问题</h3><p>所谓Evaluation问题，就是假定我们已知<span class="math inline">\(\lambda\)</span>时，评价任意序列<span class="math inline">\(O\)</span>产生的概率，也就是求条件概率<span class="math inline">\(P(O|\lambda)\)</span></p><p>直觉上看，既然<span class="math inline">\(\lambda\)</span>已知，那么根据观测独立性，我们只要知道隐状态序列<span class="math inline">\(I = \{i_1,i_2,...,i_T\}\)</span>，就可以进而求出<span class="math inline">\(O =\{o_1,o_2,...o_T\}\)</span>，所以有:</p><p><span class="math display">\[P(O|\lambda) = P(I|\lambda)P(O|I,\lambda)\]</span></p><p>我们分开来看 <span class="math display">\[p(I|\lambda)=p(i_1,i_2,\cdots,i_t|\lambda)=p(i_t|i_1,i_2,\cdots,i_{t-1},\lambda)p(i_1,i_2,\cdots,i_{t-1}|\lambda)\]</span> 根据Markov假设: <span class="math display">\[p(i_t|i_1,i_2,\cdots,i_{t-1},\lambda)=p(i_t|i_{t-1})=a_{i_{t-1}i_t}\]</span> 所以有： <span class="math display">\[p(I|\lambda)=\pi_1\prod\limits_{t=2}^Ta_{i_{t-1},i_t}\]</span> 再看第二部分 <span class="math display">\[p(O|I,\lambda)=\prod\limits_{t=1}^Tb_{i_t}(o_t)\]</span></p><p><span class="math display">\[p(O|\lambda)=\sum\limits_{I}\pi_{i_1}\prod\limits_{t=2}^Ta_{i_{t-1},i_t}\prod\limits_{t=1}^Tb_{i_t}(o_t)\]</span></p><p>上式中的<span class="math inline">\(\sum\limits_I\)</span> 实际上是在对每一步的i求和，包含了<span class="math inline">\(N^T\)</span>种轨迹，因此上面这个定义式是一个复杂度为<span class="math inline">\(O(TN^T)\)</span>的算式，这种指数复杂度肯定是不能硬解了，这时就该我们的前后向算法登场了。</p><h4 id="前向算法">前向算法</h4><p>为了方便，我们不妨计<span class="math inline">\(\alpha_t(i)=p(o_1,o_2,\cdots,o_t,i_t=q_i|\lambda)\)</span>，所以<span class="math inline">\(\alpha_T(i)=p(O,i_T=q_i|\lambda)\)</span>，根据贝叶斯公式积分即可得到<span class="math inline">\(p(O|\lambda)\)</span> <span class="math display">\[p(O|\lambda)=\sum\limits_{i=1}^Np(O,i_T=q_i|\lambda)=\sum\limits_{i=1}^N\alpha_T(i)\]</span> 不难看出，前向算法的核心就是要推出<span class="math inline">\(\alpha_T\)</span></p><p>我们先考虑<span class="math inline">\(\alpha_{t+1}(j)\)</span> <span class="math display">\[\begin{aligned}\alpha_{t+1}(j)&amp;=p(o_1,o_2,\cdots,o_{t+1},i_{t+1}=q_j|\lambda)\\&amp;=\sum\limits_{i=1}^Np(o_1,o_2,\cdots,o_{t+1},i_{t+1}=q_j,i_t=q_i|\lambda)\\&amp;=\sum\limits_{i=1}^Np(o_{t+1}|o_1,o_2,\cdots,i_{t+1}=q_j,i_t=q_i|\lambda)p(o_1,\cdots,o_t,i_t=q_i,i_{t+1}=q_j|\lambda)\end{aligned}\]</span> 因为观测独立性假设，所以<span class="math inline">\(o_{t+1}\)</span>仅与<span class="math inline">\(i_{t+1}\)</span>有关 <span class="math display">\[\begin{aligned}\alpha_{t+1}(j)&amp;=\sum\limits_{i=1}^Np(o_{t+1}|i_{t+1}=q_j)p(o_1,\cdots,o_t,i_t=q_i,i_{t+1}=q_j|\lambda)\\&amp;=\sum\limits_{i=1}^Np(o_{t+1}|i_{t+1}=q_j)p(i_{t+1}=q_j|o_1,\cdots,o_t,i_t=q_i,\lambda)p(o_1,\cdots,o_t,i_t=q_i|\lambda)\\&amp;=[\sum\limits_{i=1}^Na_{ij}\alpha_t(i)]b_{j}(o_t)\end{aligned}\]</span> 到此，我们就得到了<span class="math inline">\(\alpha\)</span>的递推公式,而<span class="math inline">\(\alpha_1(i)=\pi_ib_i(o_1)\)</span></p><p>在前向算法中，每一次递推的复杂度是N，一共进行T次递推，最后再将<span class="math inline">\(\alpha_T\)</span>进行一次积分，复杂度是N，所以前向算法的时间复杂度是<span class="math inline">\(O(TN^2)\)</span></p><h4 id="后向算法">后向算法</h4><p>与前向算法类似，我们计<span class="math inline">\(\beta_t(i)=p(o_{t+1},o_{t+1},\cdots，o_T|i_t=i,\lambda)\)</span>，接下来我们用<span class="math inline">\(\beta\)</span>来表示<span class="math inline">\(P(O|\lambda)\)</span> <span class="math display">\[\begin{aligned}p(O|\lambda)&amp;=p(o_1,\cdots,o_T|\lambda)\\&amp;=\sum\limits_{i=1}^Np(o_1,o_2,\cdots,o_T,i_1=q_i|\lambda)\\&amp;=\sum\limits_{i=1}^Np(o_1,o_2,\cdots,o_T|i_1=q_i,\lambda)\pi_i\\&amp;=\sum\limits_{i=1}^Np(o_1|o_2,\cdots,o_T,i_1=q_i,\lambda)p(o_2,\cdots,o_T|i_1=q_i,\lambda)\pi_i\\&amp;=\sum\limits_{i=1}^Nb_i(o_1)\pi_i\beta_1(i)\end{aligned}\]</span> 和前向算法一样，接下来我们推导<span class="math inline">\(\beta\)</span>递推式： <span class="math display">\[\begin{aligned}\beta_t(i)&amp;=p(o_{t+1},\cdots,o_T|i_t=q_i)\\&amp;=\sum\limits_{j=1}^Np(o_{t+1},o_{t+2},\cdots,o_T,i_{t+1}=q_j|i_t=q_i)\\&amp;=\sum\limits_{j=1}^Np(o_{t+1},\cdots,o_T|i_{t+1}=q_j,i_t=q_i)p(i_{t+1}=q_j|i_t=q_i)\\&amp;=\sum\limits_{j=1}^Np(o_{t+1},\cdots,o_T|i_{t+1}=q_j)a_{ij}\\&amp;=\sum\limits_{j=1}^Np(o_{t+1}|o_{t+2},\cdots,o_T,i_{t+1}=q_j)p(o_{t+2},\cdots,o_T|i_{t+1}=q_j)a_{ij}\\&amp;=\sum\limits_{j=1}^Nb_j(o_{t+1})a_{ij}\beta_{t+1}(j)\end{aligned}\]</span> 不难看出，后向算法的复杂度同样是<span class="math inline">\(O(N^2T)\)</span></p><h3 id="learning问题">Learning问题</h3><p>说起learning，本质就是对通过<strong>最大似然法</strong>（MLE）对参数$ $的学习过程。而这种含有隐状态的模型，自然而然的就想到用EM算法进行优化，下面我们回忆一下EM算法。</p><p>EM的最终目的是为了解决含有隐变量的混合模型的参数估计问题即 <span class="math display">\[\theta_{MLE}=\mathop{argmax}\limits_\theta\log p(x|\theta)\]</span> 它主要由不断迭代的E-step和M-step组成</p><p><strong>E-step:</strong> 计算 <span class="math inline">\(\log p(x,z|\theta)\)</span> 在概率分布 <span class="math inline">\(p(z|x,\theta^t)\)</span> 下的期望</p><p><strong>M-step:</strong>计算使这个期望最大化的参数得到<span class="math inline">\(p(z|x,\theta^{（t+1）})\)</span></p><p>EM算法可写作： <span class="math display">\[\theta^{t+1}=\mathop{argmax}_{\theta}\int_z\log p(X,Z|\theta)p(Z|X,\theta^t)dz\]</span> 在HMM中，即为 <span class="math display">\[\begin{aligned}\lambda^{(t+1)} &amp;= arg \max \limits_{\lambda}\sum\limits_{I} \log p(O,I|\lambda)p(I|O,\lambda^{t})\end{aligned}\]</span></p><p>其中由于后验项<span class="math inline">\(p(I|O,\lambda^{t})\)</span>中不含<span class="math inline">\(\lambda\)</span>,因此对上式中<span class="math inline">\(\lambda\)</span>的取值是可有可无的，所以可将原式改写为 <span class="math display">\[\begin{aligned}\lambda^{t+1} &amp;= arg \max \limits_{\lambda}\sum\limits_{I} \log p(O,I|\lambda)p(O,I|\lambda^{t})\end{aligned}\]</span> 我们下面先对<span class="math inline">\(\pi^{t+1}\)</span>进行参数估计： <span class="math display">\[\pi^{t+1}=\mathop{argmax}_\pi\sum\limits_{T}[\log \pi_{i_1}\cdot p(O,i_1...i_T|\lambda^t)]\]</span> 首先将联合概率化为边缘概率 <span class="math display">\[\pi^{t+1}=\mathop{argmax}_\pi\sum\limits_{i}[\log \pi_{i}\cdot p(O,i_1 = q_i|\lambda^t)]\]</span> 到这一步，就要用上一些技巧了。其实对于<span class="math inline">\(\pi\)</span>，是有一个约束条件的，即<span class="math inline">\(\sum\limits_i\pi_i=1\)</span> ，有了约束条件，我们就可以用拉格朗日法进行求解了。</p><p>先定义 Lagrange 函数： <span class="math display">\[ L(\pi,\eta)=\sum\limits_{i=1}^N\log \pi_i\cdot p(O,i_1=q_i|\lambda^t)+\eta(\sum\limits_{i=1}^N\pi_i-1)\]</span> 对<span class="math inline">\(\pi_i\)</span>求偏导： <span class="math display">\[\frac{\partial L}{\partial\pi_i}=\frac{1}{\pi_i}p(O,i_1=q_i|\lambda^t)+\eta=0\]</span> 自然而然的就可得到： <span class="math display">\[\pi_i^{t+1}=\frac{p(O,i_1=q_i|\lambda^t)}{p(O|\lambda^t)}\]</span> 对<span class="math inline">\(A^{t+1}\)</span>和<span class="math inline">\(B^{t+1}\)</span>也是类似的方法，只是计算会更加繁琐一些。</p><p>以上就是HMM中的EM算法，也叫<strong>Baum-Welch</strong>算法。</p><h3 id="decoding问题">Decoding问题</h3><p>所谓decoding问题，就是在已知观测序列的情况下，预测隐状态序列即<span class="math inline">\(P(I|O)\)</span> <span class="math display">\[I=\mathop{argmax}\limits_{I}P(I|O,\lambda)\]</span> 实质上就是要求我们找到一个序列,使其概率最大，用老师的话讲，就是在参数空间中找到一条最短路径，这实质上就可以转化成动态规划问题来求解，也就是著名的<strong>维特比算法</strong>（Viterbi algorithm）</p><p>首先定义<span class="math inline">\(\delta\)</span>，它表征的是，<span class="math inline">\(i_t\)</span>已知时，到达<span class="math inline">\(i_t\)</span>的最大概率 <span class="math display">\[\delta_{t}(j)=\max\limits_{i_1,\cdots,i_{t-1}}p(o_1,\cdots,o_t,i_1,\cdots,i_{t-1},i_t=q_i)\]</span> 由于观测独立性和其次马尔可夫性，能得到<span class="math inline">\(\delta\)</span>的递推式 <span class="math display">\[\delta_{t+1}(j)=\max\limits_{1\le i\le N}\delta_t(i)a_{ij}b_j(o_{t+1})\]</span> 但<span class="math inline">\(\delta\)</span>只是一个概率值，我们还需要定义<span class="math inline">\(\psi\)</span>来记录节点，<span class="math inline">\(\psi_{t+1}\)</span>表示了在前面的路径都已知时，下一时刻最可能到达的隐状态 <span class="math display">\[\psi_{t+1}(j)=\mathop{argmax}\limits_{1\le i\le N}\delta_t(i)a_{ij}\]</span></p><h3 id="reference">Reference</h3><p><a href="https://anxiang1836.github.io/2019/11/05/NLP_From_HMM_to_CRF/" target="_blank" rel="noopener">【NLP】从隐马尔科夫到条件随机场</a></p><p><a href="https://www.cnblogs.com/pinard/p/6955871.html" target="_blank" rel="noopener">隐马尔科夫模型HMM（二）前向后向算法评估观察序列概率</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要整理自shuhuai008大佬的&lt;a href=&quot;https://space.bilibili.com/97068901&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;白班推导&lt;/a&gt;的版书和《统计学习方法》第九章HMM&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="NLP" scheme="http://freemty.github.io/tags/NLP/"/>
    
      <category term="Machine Learning" scheme="http://freemty.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>用StyleGAN来生成浮世绘</title>
    <link href="http://freemty.github.io/2020/02/27/gan-ukiyo-generator/"/>
    <id>http://freemty.github.io/2020/02/27/gan-ukiyo-generator/</id>
    <published>2020-02-27T10:20:50.000Z</published>
    <updated>2022-02-11T12:51:21.982Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h4 id="gan的原理补充"><a class="markdownIt-Anchor" href="#gan的原理补充"></a> GAN的原理补充</h4><h4 id="浮世绘图像生成"><a class="markdownIt-Anchor" href="#浮世绘图像生成"></a> 浮世绘图像生成</h4><h5 id="ukiyo-e-faces-数据集"><a class="markdownIt-Anchor" href="#ukiyo-e-faces-数据集"></a> Ukiyo-E Faces 数据集</h5><p>​    这次实验用到的是“Ukiyo-e faces dataset”。也是恰好找到了一个可以用且足够有趣的数据集。这是一个浮世绘数据集,是作者Justin Pinkney是从各大博物馆以及相关网站中爬下来的几千张浮世绘图片。但由于数据来源十分广泛,图片的质量和尺寸是千奇百怪,这里为了方便训练,作者专门使用了基于ESRGAN的分辨率增强模型,将所有图片统一到了1024X1024的分辨率,最终得到了一个5024张的浮世绘数据集,数据集的预览如图</p><img src="/2020/02/27/gan-ukiyo-generator/Users/sum_young/private_code/blog/source/_posts/figure/overview.jpeg" alt="数据集预览图" style="zoom: 25%;"><p>​    就直观来看,利用这个浮世绘数据集来微调StyleGAN的可行性还是蛮高的,一来作为艺术作品,它的颜色风格相比于真实世界还是要更为固定一些,数据集中的人像质量都很高,风格也都较为统一,例如男性的发型和面部的朝向大致可以划分为几种常见的风格,面部的颜色也基本相同,此外作为一个微调任务,5000张高质量人像已经算很充足了。</p><h5 id="模型结构"><a class="markdownIt-Anchor" href="#模型结构"></a> 模型结构</h5><p>​    由于模型比较大,很难直观的输出参数,不过好在使用的这个英伟达在github上的放出的模型是用Tensorflow写成的,因此可以很直观的使用TF中的Tensofboard可视化的输出整个模型结构。使用Tensorboard输出整个模型如图[\ref{fig:model}],可以看到模型主题是由输入映射网络<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">G_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,渐进式生成网络<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">G_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和判别器<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>所构成的。</p><img src="/2020/02/27/gan-ukiyo-generator/Users/sum_young/private_code/blog/source/_posts/figure/model.png" style="zoom:25%;"><p>​        生成器<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">G_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的内部结构如图所示,可以看到生成器中所串联的由<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn><mo>×</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">4\times4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span>一直到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>256</mn><mo>×</mo><mn>256</mn></mrow><annotation encoding="application/x-tex">256 \times 256</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord">5</span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">5</span><span class="mord">6</span></span></span></span>的分辨率不断提高的生成层,此外,每个生成层左侧所额外连接的输入即为StyleGAN中控制图像风格的噪音输入。</p><img src="/2020/02/27/gan-ukiyo-generator/Users/sum_young/private_code/blog/source/_posts/figure/gs.png" style="zoom:30%;"><h5 id="训练过程"><a class="markdownIt-Anchor" href="#训练过程"></a> 训练过程</h5><p>​    这里参考了其他博主的微调经验之后。我选取了英伟达已经在FFHQ上训练完成的人像生成模型作为基准。在此基础上使用浮世绘数据集进行微调。FFHQ数据如图所示,其中包含了7万张1024分辨率的高清晰度人像。</p><h4 id="浮世绘风格的现代人像生成"><a class="markdownIt-Anchor" href="#浮世绘风格的现代人像生成"></a> 浮世绘风格的现代人像生成</h4><h4 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h4><p>[使用StyleGAN训练自己的数据集]<a href="https://shartoo.github.io/2019/05/12/edit-stylegan-humanface/" target="_blank" rel="noopener">https://shartoo.github.io/2019/05/12/edit-stylegan-humanface/</a></p><p>[Ukiyo-e faces数据集]<a href="https://www.justinpinkney.com/ukiyoe-dataset/" target="_blank" rel="noopener">https://www.justinpinkney.com/ukiyoe-dataset/</a></p><p>[模型融合方法]<a href="https://www.justinpinkney.com/stylegan-network-blending/" target="_blank" rel="noopener">https://www.justinpinkney.com/stylegan-network-blending/</a></p><p>[StyleGAN:A Style-Based Generator Architecture for Generative Adversarial Networks]</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h4 id=&quot;gan的原理补充&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#gan的原理补充&quot;&gt;&lt;/a&gt; GAN的原理补充&lt;/h4&gt;
&lt;h4 id=&quot;浮世绘图像生成&quot;&gt;&lt;a class=&quot;markdownIt-A
      
    
    </summary>
    
    
    
      <category term="CV" scheme="http://freemty.github.io/tags/CV/"/>
    
      <category term="personal tiny project" scheme="http://freemty.github.io/tags/personal-tiny-project/"/>
    
  </entry>
  
  <entry>
    <title>用LSTM实现唐诗生成</title>
    <link href="http://freemty.github.io/2020/02/27/rnn-poem-generator/"/>
    <id>http://freemty.github.io/2020/02/27/rnn-poem-generator/</id>
    <published>2020-02-27T10:20:50.000Z</published>
    <updated>2022-02-11T12:35:52.134Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;

      
    
    </summary>
    
    
    
      <category term="NLP" scheme="http://freemty.github.io/tags/NLP/"/>
    
      <category term="personal tiny project" scheme="http://freemty.github.io/tags/personal-tiny-project/"/>
    
  </entry>
  
  <entry>
    <title>「Paper-Reading」seqGAN——将GAN与Policy Gradient带入NLP领域</title>
    <link href="http://freemty.github.io/2020/02/27/seqGAN/"/>
    <id>http://freemty.github.io/2020/02/27/seqGAN/</id>
    <published>2020-02-27T10:20:50.000Z</published>
    <updated>2022-02-11T12:49:48.031Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间使用上交开源的seqGAN重新实现了Poem Generator,这几天回头细读一下文章</p><a id="more"></a><h3 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h3><h3 id="proposed-model"><a class="markdownIt-Anchor" href="#proposed-model"></a> Proposed Model</h3><p>为了方便阅读，我们先记</p><ul><li>discriminator <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span></li><li>generator <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span></span></span></span></li><li>vocabulary <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span></span></span></span></li><li>a sequence <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>t</mi></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>T</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>y</mi><mi>t</mi></msub><mo>∈</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">Y_{1:T} = (y_1,...,y_t,...,y_T),y_t ∈ \gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span></span></span></span></li><li>current state <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mo>=</mo><msub><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s = Y_{1:t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>(当前的状态为之前所有输出tokens的序列)</li><li>next state <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>s</mi><mo separator="true">,</mo></msup><mo>=</mo><msub><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s^{,} = Y_{1:t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43689199999999995em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.43689199999999995em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mpunct mtight">,</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li><li>action <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mo>=</mo><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a = y_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li></ul><p>在上面的预设下，所有Text-Generation类任务，都可以抽象化为在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">t</span></span></span></span>时刻，已经生成<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>y</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(y_1,..y_{t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>的基础上，采取什么action（如何选取<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">y_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）。</p><h4 id="seqgan-via-policy-gradient"><a class="markdownIt-Anchor" href="#seqgan-via-policy-gradient"></a> SeqGAN via Policy Gradient</h4><p>生成器有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G_\theta(y_t|Y_{1:t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><br>在对抗学习的情境下，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span></span></span></span> 目标函数是</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&lt;</mo><mi>E</mi><mi>m</mi><mi>p</mi><mi>t</mi><mi>y</mi><mtext> </mtext><mi>M</mi><mi>a</mi><mi>t</mi><mi>h</mi><mtext> </mtext><mi>B</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mo>&gt;</mo></mrow><annotation encoding="application/x-tex">&lt;Empty \space Math \space Block&gt;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">m</span><span class="mord mathdefault">p</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace"> </span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span></span></span></span></span></p><p>那么<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>是怎么计算每一步的value的呢？</p><p>可这样的话，Discriminator只能对一整个seq进行判别<br>这里就要Rollout Policy出场了</p><p>在前<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>时刻</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>Q</mi><msub><mi>D</mi><mi>ϕ</mi></msub><msub><mi>G</mi><mi>θ</mi></msub></msubsup><mo stretchy="false">(</mo><mi>a</mi><mo>=</mo><msub><mi>y</mi><mi>t</mi></msub><mo separator="true">;</mo><mi>s</mi><mo>=</mo><msub><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>D</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><msubsup><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi></mrow><mi>n</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q^{G_\theta}_{D_\phi}(a = y_t;s = Y_{1:t-1}) =\frac{1}{N}\sum^{N}_{n=1}D_\phi(Y_{1:T}^{n})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4256019999999998em;vertical-align:-0.4966109999999999em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9289909999999999em;"><span style="top:-2.4064690000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29011428571428566em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.1506600000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4966109999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0954490000000003em;vertical-align:-1.267113em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>其中</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi></mrow><mi>n</mi></msubsup></mrow><annotation encoding="application/x-tex">Y_{1:T}^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9613919999999999em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>最后的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span></span>时刻，由于，序列已经生成了，就不用</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>Q</mi><msub><mi>D</mi><mi>ϕ</mi></msub><msub><mi>G</mi><mi>θ</mi></msub></msubsup><mo stretchy="false">(</mo><mi>a</mi><mo>=</mo><msub><mi>y</mi><mi>T</mi></msub><mo separator="true">;</mo><mi>s</mi><mo>=</mo><msub><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>D</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><msub><mi>Y</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> Q^{G_\theta}_{D_\phi}(a = y_T;s = Y_{1:T-1}) = D_\phi(Y_{1:T})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4256019999999998em;vertical-align:-0.4966109999999999em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9289909999999999em;"><span style="top:-2.4064690000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29011428571428566em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.1506600000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4966109999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>是在看完代码之后，才明白在Rollout里面也保存着一套LSTM，这就是paper中说的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>β</mi></msub></mrow><annotation encoding="application/x-tex">G_\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，</p><h4 id="step"><a class="markdownIt-Anchor" href="#step"></a> Step</h4><p>先用MLE去预训练<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">G_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，再用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">G_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>生成的“赝品”和真实数据共同去预训练<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>ϕ</mi></msub></mrow><annotation encoding="application/x-tex">D_\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></p><p>action value function : <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>Q</mi><msub><mi>D</mi><mi>ϕ</mi></msub><msub><mi>G</mi><mi>θ</mi></msub></msubsup><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q^{G_\theta}_{D_\phi}(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4256019999999998em;vertical-align:-0.4966109999999999em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9289909999999999em;"><span style="top:-2.4064690000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29011428571428566em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.1506600000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4966109999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span></span></span></span></p><img src="/2020/02/27/seqGAN/figure/seqgan.png" style="zoom:30%;">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前段时间使用上交开源的seqGAN重新实现了Poem Generator,这几天回头细读一下文章&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="NLP" scheme="http://freemty.github.io/tags/NLP/"/>
    
      <category term="RL" scheme="http://freemty.github.io/tags/RL/"/>
    
      <category term="paper reading" scheme="http://freemty.github.io/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>seqGAN后续——代码阅读+重构新版PoemGenerator</title>
    <link href="http://freemty.github.io/2020/02/27/seqGAN-code/"/>
    <id>http://freemty.github.io/2020/02/27/seqGAN-code/</id>
    <published>2020-02-27T10:20:50.000Z</published>
    <updated>2022-02-11T12:48:24.717Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><p>这是上一篇paper-reading的后续。在NLG中，强化学习肯定是相当重要的一种思路，因此GAN的实现还是相当有必要的，而seqGAN可以说是的文本GAN中的baseline了（leakGAN maskGAN etc.）所以这几天半抄半改的复现了seqGAN，并在上面跑了一下全唐诗（相比之下自己以前的LSTM-Generator纯属小玩具orz）。</p><h2 id="code"><a class="markdownIt-Anchor" href="#code"></a> Code</h2><p>在读了seqGAN的代码的基础上，我也根据自己的习惯小幅重构了一下，也方便加深理解</p><h3 id="build-generator"><a class="markdownIt-Anchor" href="#build-generator"></a> build Generator</h3><p>说实话我并不理解这里作者为什么要手撸一个LSTM（肯定不是不会用API XD）<br>我目前的理解是直接用<code>tf.nn.rnn.LSTMcell</code>的话不方便向Rollout中的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>β</mi></msub></mrow><annotation encoding="application/x-tex">G_\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>传Variable。不过代码里很多tf函数的用法也还是第一次见到，学到了不少。</p><h4 id="unrolled-rnn-unit"><a class="markdownIt-Anchor" href="#unrolled-rnn-unit"></a> Unrolled RNN unit</h4><p><code>start token</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用TensorArray便于读写</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">gen_o = tf.TensorArray(dtype=tf.float32, size=self.c,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">                                        dynamic_size=<span class="literal">False</span>, infer_shape=<span class="literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">gen_x = tf.TensorArray(dtype=tf.int32, size=self.config.seq_maxlen,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">                                        dynamic_size=<span class="literal">False</span>, infer_shape=<span class="literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#unrolled lstm </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">_, _, _, self.gen_o, self.gen_x = tf.while_loop(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    cond=<span class="keyword">lambda</span> i, _1, _2, _3, _4: i &lt; </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    self.sequence_length,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    body=_g_recurrence, </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    loop_vars=(tf.constant(<span class="number">0</span>, dtype=tf.int32),</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">            tf.nn.embedding_lookup(self.g_embeddings, self.start_token), self.h0, gen_o, gen_x))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">self.gen_x = self.gen_x.unstack()</span></pre></td></tr></table></figure><p>这里的<code>tf.while_loop</code>还是第一次见到orz,详解见<a href="https://blog.csdn.net/u011509971/article/details/78805727" target="_blank" rel="noopener">这里</a>简单说一下把，<code>tf.while_loop</code>函数中<code>cond</code>和<code>body</code>分别是进行判别和执行操作的函数，他们都会接收<code>loop_vars</code>中的所有参数，所以要注意参数的位置和数量的一致</p><h4 id="pretrain-loss"><a class="markdownIt-Anchor" href="#pretrain-loss"></a> pretrain loss</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">self.pretrain_loss = -tf.reduce_sum(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    tf.one_hot(tf.to_int32(tf.reshape(self.x, [<span class="number">-1</span>])), self.num_emb, <span class="number">1.0</span>, <span class="number">0.0</span>) * tf.log(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">            tf.clip_by_value(tf.reshape(self.g_predictions, [<span class="number">-1</span>, self.num_emb]), <span class="number">1e-20</span>, <span class="number">1.0</span>)</span></pre></td></tr></table></figure><h3 id="build-discriminator"><a class="markdownIt-Anchor" href="#build-discriminator"></a> build Discriminator</h3><p>discriminator的任务就是对于生成的文本输出一个介于0和1之间的分值，在本次的seqGAN中Discriminator使用了一个多层CNN用来执行分类任务</p><h4 id="cnn-unit"><a class="markdownIt-Anchor" href="#cnn-unit"></a> CNN unit</h4><p>说实话，炼丹这么久了，CNN正经一点了解都没有，真是太丢人了。<br>就在这里顺道学一下CNN吧</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">pooled_outputs = []</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> filter_size, num_filter <span class="keyword">in</span> zip(filter_sizes, num_filters):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"conv-maxpool-%s"</span> % filter_size):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">        <span class="comment"># Convolution Layer</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">        filter_shape = [filter_size, embedding_size, <span class="number">1</span>, num_filter]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">        W = tf.Variable(tf.truncated_normal(filter_shape, stddev=<span class="number">0.1</span>), name=<span class="string">"W"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">        b = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[num_filter]), name=<span class="string">"b"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">        conv = tf.nn.conv2d(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">            self.embedded_chars_expanded,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">            W,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">            strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">            padding=<span class="string">"VALID"</span>,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">            name=<span class="string">"conv"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">        <span class="comment"># Apply nonlinearity</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">        h = tf.nn.relu(tf.nn.bias_add(conv, b), name=<span class="string">"relu"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">        <span class="comment"># Maxpooling over the outputs</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">        pooled = tf.nn.max_pool(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">            h,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">            ksize=[<span class="number">1</span>, sequence_length - filter_size + <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">            strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">            padding=<span class="string">'VALID'</span>,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">            name=<span class="string">"pool"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">        pooled_outputs.append(pooled)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># Combine all the pooled features</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">num_filters_total = sum(num_filters)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">self.h_pool = tf.concat(pooled_outputs, <span class="number">3</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">self.h_pool_flat = tf.reshape(self.h_pool, [<span class="number">-1</span>, num_filters_total])</span></pre></td></tr></table></figure><p>这里的输入x是sequence已经被展开到一维的embeddings。这里的多层CNN就能将一个长度为<code>embed_size * seq_len</code>的向量降到</p><h4 id="highway-unit"><a class="markdownIt-Anchor" href="#highway-unit"></a> Highway unit</h4><p>highway层为了加快收敛而添加的</p><p>关于highway，我参考了<a href="https://zhuanlan.zhihu.com/p/35019701" target="_blank" rel="noopener">这里</a>，paper原文在<a href="http://arxiv.org/abs/1505.00387" target="_blank" rel="noopener">这里</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr></table></figure><h3 id="roll-out"><a class="markdownIt-Anchor" href="#roll-out"></a> Roll out</h3><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span></span></span></span>都构建完成，就要开始rollout了，Rollout在初始化时，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>β</mi></msub></mrow><annotation encoding="application/x-tex">G_\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>会接受一整套预训练完成的Generator的LSTM，作为初始值。</p><p>在更新时，update-rate就上场了，在update时，rollout中的LSTM并不是原样接收<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">G_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中的值，而是部分保留，部分更新</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">G_bate = G_beta * (<span class="number">1</span> - updata_rate) + G_theta * update_rate</span></pre></td></tr></table></figure><h4 id="get-rawards"><a class="markdownIt-Anchor" href="#get-rawards"></a> Get rawards</h4><p>这里可以说是seqGAN的核心function</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_reward</span><span class="params">(self, sess, input_x, rollout_num, discriminator)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    rewards = []</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(rollout_num):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#D开始对生成sample中的每个token打分</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">for</span> given_num <span class="keyword">in</span> range(<span class="number">1</span>, self.sequence_length ):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">        <span class="comment"># t &lt; t 时 会使用G_beta生成token补全sequesnce</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">            feed = &#123;self.x: input_x, self.given_num: given_num&#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">            samples = sess.run(self.gen_x, feed)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">            feed = &#123;discriminator.input_x: samples, discriminator.dropout_keep_prob: <span class="number">1.0</span>&#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">            ypred_for_auc = sess.run(discriminator.ypred_for_auc, feed)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">            ypred = np.array([item[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> ypred_for_auc])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">                rewards.append(ypred)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">                <span class="comment">#第一轮rollout生成打分栏</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">            <span class="keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">                rewards[given_num - <span class="number">1</span>] += ypred</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">                <span class="comment">#后面直接往上加</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">        <span class="comment"># the last token reward</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">        feed = &#123;discriminator.input_x: input_x, discriminator.dropout_keep_prob: <span class="number">1.0</span>&#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">        ypred_for_auc = sess.run(discriminator.ypred_for_auc, feed)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">        ypred = np.array([item[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> ypred_for_auc])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">            rewards.append(ypred)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">            <span class="comment"># completed sentence reward</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">            rewards[self.sequence_length - <span class="number">1</span>] += ypred</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">    rewards = np.transpose(np.array(rewards)) / (<span class="number">1.0</span> * rollout_num)  </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#batch_size x seq_length</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">return</span> rewards</span></pre></td></tr></table></figure><h3 id="optimize"><a class="markdownIt-Anchor" href="#optimize"></a> Optimize</h3><p>获得了reward之后，就要开始优化了</p><p>着重读一下这几个loss吧</p><h3 id="run"><a class="markdownIt-Anchor" href="#run"></a> RUN</h3><p>基本模块都完成了，现在就开始GAN吧！<br>先理一下训练流程</p><h4 id="adversial-train"><a class="markdownIt-Anchor" href="#adversial-train"></a> Adversial Train</h4><p>这是一个epoch的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">1</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    samples = generator.generate(sess)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#注意，一次generate生成一整个seqence个而非一个token</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">    rewards = rollout.get_reward(sess, samples, <span class="number">16</span>, discriminator)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    feed = &#123;generator.x: samples, generator.rewards: rewards&#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    _ = sess.run(generator.g_updates, feed_dict=feed)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> total_batch % <span class="number">5</span> == <span class="number">0</span> <span class="keyword">or</span> total_batch == TOTAL_BATCH - <span class="number">1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    generate_samples(sess, generator, BATCH_SIZE, generated_num, eval_file)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    likelihood_data_loader.create_batches(eval_file)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    test_loss = target_loss(sess, target_lstm, likelihood_data_loader)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># Update roll-out parameters</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">rollout.update_params()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train the discriminator</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    generate_samples(sess, generator, BATCH_SIZE, generated_num, negative_file)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    dis_data_loader.load_train_data(positive_file, negative_file)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">3</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">        dis_data_loader.reset_pointer()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">for</span> it <span class="keyword">in</span> xrange(dis_data_loader.num_batch):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">            x_batch, y_batch = dis_data_loader.next_batch()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">            feed = &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">                discriminator.input_x: x_batch,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">                discriminator.input_y: y_batch,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">                discriminator.dropout_keep_prob: dis_dropout_keep_prob</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">            &#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">            _ = sess.run(discriminator.train_op, feed)</span></pre></td></tr></table></figure><h3 id="orcal-lstm"><a class="markdownIt-Anchor" href="#orcal-lstm"></a> Orcal LSTM</h3><p>说实话，刚看代码的时候，一直不明白source里的<code>target_lstm.py</code>是干嘛的，还以为是作者写的LSTM的模版，最后重读了一边论文，才发现这部分的作用。原文在实验的时候引入了orcale-model，说白了就是他们有一个在目标任务上预训练的相当成熟的LSTM可以直接生成正样本相比于从零开始,模型收敛会快上不少，而我在跑Chinese-Poem的时候，这部分肯定就没有了。</p><h3 id="others"><a class="markdownIt-Anchor" href="#others"></a> others</h3><h4 id="data-until"><a class="markdownIt-Anchor" href="#data-until"></a> data until</h4><p>这次用的数据是ChinesePoem<a href="http://homepages.inf.ed.ac.uk/mlap/Data/EMNLP14/rnnpg_data_emnlp-2014.tar.bz2" target="_blank" rel="noopener">下载</a><br>有28W首。<br>数据以40为单位做了切分，并做了mask</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;这是上一篇paper-reading的后续。在NLG中，强化学习肯定是相当重要的一种思路，因此GAN的实现还是相当有必要的，而seqGAN可以说是的文本GAN中的baseline了（leakGAN maskGAN etc.）所以这几天半抄
      
    
    </summary>
    
    
    
      <category term="NLP" scheme="http://freemty.github.io/tags/NLP/"/>
    
      <category term="RL" scheme="http://freemty.github.io/tags/RL/"/>
    
      <category term="paper reading" scheme="http://freemty.github.io/tags/paper-reading/"/>
    
      <category term="personal tiny project" scheme="http://freemty.github.io/tags/personal-tiny-project/"/>
    
  </entry>
  
  <entry>
    <title>兜兜转转又一年</title>
    <link href="http://freemty.github.io/2020/02/19/twenty/"/>
    <id>http://freemty.github.io/2020/02/19/twenty/</id>
    <published>2020-02-18T17:27:37.000Z</published>
    <updated>2022-02-08T12:58:48.783Z</updated>
    
    <content type="html"><![CDATA[<p>  敲字儿这会儿，已经过了零点了，20岁了</p><a id="more"></a><p>  对于所谓“成长”的记忆大都来自书本和电影，印象最深的就是小时候在电视上看《少林寺》，李连杰在一个过场里冬练三九夏练三伏，日日精进，绝圣弃智，三分钟bgm过后，他就蜕变成一个健壮的武僧了。</p><p>  但回到自己身上，或许是因为生活太安逸，对所谓成年，所谓长大，从未真正的体验过，空有道理而无感受。这是值得警惕的，这一年的经历让你开始明白，缺乏感受的生活必将浑浑噩噩。<strong>希望这些下面这些矫情的话可以帮你在未来的某一天唤起斗志</strong>。</p><p>  说起今年最大的遗憾，是上半年因为自己的懈怠，错失了一个可能相当宝贵的机会，无法与那群优秀的同龄人们一起同行共事，再回想起去年这个时候为了它而做出的努力，不得不说，挫败感还是相当重的。不过既然骰子已掷出，没资格后悔。</p><p>  今年或者说这大学这两年，真的没有什么值得骄傲的东西，十分害怕自己或许冥冥之中已经接受了某种平庸。。。</p><p>  在对自己的认识上，你是相对早慧的，你很早就明白那些让自己焦虑的因素是什么，来自何处，并且很早就学会了为自己在彼岸编织“解脱”之道。可惜的是，由于懒惰与自满，自己不断的食言，以至于你需要一次又一次为自己编织新的“未来”，来满足一种脆弱的优越。在2019年，这种循环已经走到了边缘，一次次的挫败已经开始触及你最宝贵的东西——真诚与自信。</p><p>  那些你曾经乐此不疲的“豪言壮志”，已经成为最值得警惕的敌人，<strong>这种虚假的达成感在真正的减损你日常生活中实践的效率</strong>，它让你无法分辨真正的“好”与廉价的“爽”，在虚假的自洽中变得自满，遮蔽真实的感受。</p><p>  用一个牵强的比喻，沉迷“抖音”没什么值得警惕的，因为大家都处在很自知的“玩物丧志”中，但凡才及中人，都有能力抽身而出。相比之下，“b站”“知乎”之流才是糟糕的，它让人沉溺在虚假的达成感中而不自知，反倒开始自欺欺人的辩解，力图争夺虚幻的优越而忘记真正的实践。（好吧我承认这个比喻实在有够奇怪，明白意思就好）</p><p>  在以后的日子里，一定要记住，不凡绝不可能在一节慷慨的进行曲中开开心心的达成。再热爱的事也要在枯燥的实践中才能达成，“好”与“爽”是不可能同时得到。</p><p>  另一方面，不要再妄自菲薄，很多与他人无意义的比较只会减损斗志，<strong>少说多做</strong>才会带来好的感受，要用感受而非思辨去对抗那种自卑与懒惰。</p><p>  好在你终究还是抱有着最后一丝自信力，那股劲儿还在。下半年拾起了长跑，坚持了几个月没有懈怠，是值得开心的。现在的每月130公里，确实是最初不敢想的，实属不易，等这段日子过去，要继续精进，不要放下！</p><p>  大道理讲完了，再说说实际的期许吧。在学业上，如果真的对NLP有热忱，一定要分秒必争（不出意外明年这个时候就要准备考研了，ZJU等我）本科也就剩这一年可以专心学习了，不要害怕自己资源或者资质不够，属于自己的道路只能是独自摸索出来的，有很多未知的好运真的只有在实践的路上才能遇到。</p><pre><code>“怕什么真理无穷，进一寸有一寸的欢喜”</code></pre><p>（胡适这句话虽然被用烂了，但不得不说确实是催人奋进的）</p><p>  在运动上，关于跑步的两个小目标，校运会10km拿名次和一场马拉松总是要做到的（提前祈祷杭马或者宁马能中签），运动时的那种专注与真诚是相当很珍贵的。</p><p>  最后就是对生活的一些期许了，这一年和身边人的关系大都若即若离，接下来的一年希望不论是技术上还是观念上都可以遇到值得相处的人。此外在人们越来越抗拒真诚的社会中，亲密关系中的袒露变得越来越不可或缺，就像坨式所讲「“人们不能用禁闭自己的邻人来确认自己神志健全。”」只有在与人真诚的分享中我们才能真正的找到自己。一言蔽之如果身边真的有心仪的姑娘，别再怂了。</p><p>  要说的差不多了，希望新的一年可以不负所言，用实践的感受来对抗虚无，用真实的袒露来克服孤独，“中道”必然蕴藏在实践和感受当中。好了不早了，就这样吧，新的一岁，祝武运昌隆！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  敲字儿这会儿，已经过了零点了，20岁了&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="随笔" scheme="http://freemty.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>sum的强化学习(RL)笔记</title>
    <link href="http://freemty.github.io/2020/01/28/RL1/"/>
    <id>http://freemty.github.io/2020/01/28/RL1/</id>
    <published>2020-01-28T03:16:50.000Z</published>
    <updated>2022-02-11T12:18:48.500Z</updated>
    
    <content type="html"><![CDATA[<p>前一段时间开始seqGAN第一次接触到RL，正好寒假时间富裕，补一些强化学习的基础 <a id="more"></a></p><h2 id="key-concepts">Key Concepts</h2><p>在正式开始RL前,我们先要对强化学习的一些基本概念和目标有所了解，其中主要的，如果对基本概念有不理解可以看<a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html#key-concepts" target="_blank" rel="noopener">这里</a></p><ul><li><span class="math inline">\(s \in \mathcal{S}\)</span> <strong>states</strong>；<span class="math inline">\(a \in \mathcal{A}\)</span> <strong>actions</strong>；<span class="math inline">\(r \in \mathcal{R}\)</span> <strong>rewards</strong> ；<span class="math inline">\(\pi\)</span> <strong>Policy</strong></li><li><span class="math inline">\(P(s&#39;, r \vert s, a)\)</span> <strong>state-transition</strong>在状态<span class="math inline">\(s\)</span>下采取行动<span class="math inline">\(a\)</span>后转移到状态<span class="math inline">\(s&#39;\)</span>的概率<br><span class="math display">\[P_{ss&#39;}^a = P(s&#39; \vert s, a)  = \mathbb{P} [S_{t+1} = s&#39; \vert S_t = s, A_t = a] = \sum_{r \in \mathcal{R}} P(s&#39;, r \vert s, a)\]</span></li><li><span class="math inline">\(R\)</span> <strong>Reward Function</strong> <span class="math display">\[R(s, a) = \mathbb{E} [R_{t+1} \vert S_t = s, A_t = a] = \sum_{r\in\mathcal{R}} r \sum_{s&#39; \in \mathcal{S}} P(s&#39;, r \vert s, a)\]</span></li><li><span class="math inline">\(G_t\)</span> <strong>Return</strong> <span class="math display">\[G_t = \sum_{k=0}^{\infty} \gamma^k R_{t+k+1}\]</span></li><li><p><span class="math inline">\(\gamma\)</span> <strong>discounting factor</strong> <span class="math inline">\(\gamma \in [0, 1]\)</span></p></li><li><span class="math inline">\(Q^\pi(s, a)\)</span> <strong>Action Value</strong>(“Q-value”) 采取策略<span class="math inline">\(\pi\)</span>时，状态<span class="math inline">\(s\)</span>下，执行<span class="math inline">\(a\)</span>的累计回报 <span class="math display">\[Q^\pi(s, a) = \mathbb{E}_{a\sim \pi} [G_t \vert S_t = s, A_t = a]\]</span></li><li><span class="math inline">\(V^\pi(s)\)</span> <strong>State Value</strong>采取策略<span class="math inline">\(\pi\)</span>时,状态<span class="math inline">\(s\)</span>下的累计回报;也可写作<span class="math inline">\(Q(s)\)</span> <span class="math display">\[V^\pi (s) = \mathbb{E}_{a\sim \pi} [G_t \vert S_t = s]= \sum_{a \in \mathcal{A}} Q_{\pi}(s, a) \pi(a \vert s)\]</span></li><li><p><span class="math inline">\(A(s, a)\)</span> <strong>Advantage Function</strong>,（“A-value”）,定义为<span class="math inline">\(A(s, a) = Q(s, a) - V(s)\)</span></p></li></ul><h3 id="mdp">MDP</h3><p>RL的几乎所有任务都可抽象成马尔可夫过程（Markov Decision Process, MDP）</p><p><span class="math display">\[\mathbb{P}[ S_{t+1} \vert S_t ] = \mathbb{P} [S_{t+1} \vert S_1, \dots, S_t]\]</span></p><p>看似上式中的<span class="math inline">\(s_{t+1}\)</span>是一个套娃，是由之前所有时刻的状态得到的，但这里有一个关键点，一旦<span class="math inline">\(s_t\)</span>已知，便可由<span class="math inline">\(s_t\)</span>独立推出<span class="math inline">\(s_{t+1}\)</span>，之前的状态都可以扔掉。因此Text Generation这样的NLP任务并不具备马尔可夫性质(我猜)。</p><p>马尔可夫决策过程由<span class="math inline">\((S,A,P,R,\gamma)\)</span>组成，<span class="math inline">\(S\)</span>为有限的状态集,<span class="math inline">\(A\)</span> 为有限的动作集, <span class="math inline">\(P\)</span> 为状态转移概率, <span class="math inline">\(R\)</span>为回报函数, <span class="math inline">\(\gamma\)</span> 为折扣因子，用来计算累积回报（Return）</p><p>下面这个式子就是马尔可夫过程的核心了。值得注意的是状态转移的过程中，假定我们在状态<span class="math inline">\(s\)</span>这个节点上，我们采取行动<span class="math inline">\(a\)</span>，状态转移为<span class="math inline">\(s&#39;\)</span>的概率不是0或1，而是一个随机变量。 <span class="math display">\[p_{s\hat s}^a=p(\hat s|s,a)=p(S_{t+1}=\hat s| S_t=s,A_t=a)\]</span></p><h4 id="stationary-distribution">Stationary Distribution</h4><p>稳态分布（Stationary Distribution）在后面的policy gradient会用到，他是这么定义的：<strong>如果一个非周期马氏链具有概率转移矩阵 P，且它的任何两个状态都是连通的，则 <span class="math inline">\(\lim\limits_{n\to\infty}P_{ij}^n\)</span> 存在且与<span class="math inline">\(i\)</span>无关</strong>，用人话说就是服从<span class="math inline">\(\pi\)</span>马尔可夫链不同的初始概率分布经过足够长的时间都可可以收敛到一个相同的概率分布，这就是稳态分布<span class="math inline">\(d_\pi\)</span>。</p><h4 id="bellman-equation">Bellman Equation</h4><p>一言蔽之，就是对所有的状态转移与回报建立模型，表示出在马尔可夫链中的的任意<span class="math inline">\(s\)</span>点时的<span class="math inline">\(V(s)\)</span></p><p><span class="math display">\[\begin{aligned}V(s) &amp;= \mathbb{E}[G_t \vert S_t = s] \\&amp;= \mathbb{E} [R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + \dots \vert S_t = s] \\&amp;= \mathbb{E} [R_{t+1} + \gamma (R_{t+2} + \gamma R_{t+3} + \dots) \vert S_t = s] \\&amp;= \mathbb{E} [R_{t+1} + \gamma G_{t+1} \vert S_t = s] \\&amp;= \mathbb{E} [R_{t+1} + \gamma V(S_{t+1}) \vert S_t = s]\end{aligned}\]</span> <img src="/2020/01/28/RL1/bellman_equation.png" alt="bellman"></p><h4 id="优化目标">优化目标</h4><p>在这类MDP问题中，我们优化的目标无非是找到policy以获得最大的Return，计作<span class="math inline">\(V_*(s)\)</span>。</p><p><span class="math display">\[\begin{aligned}V_*(s) &amp;= \max_{a \in \mathcal{A}} Q_*(s,a)\\Q_*(s, a) &amp;= R(s, a) + \gamma \sum_{s&#39; \in \mathcal{S}} P_{ss&#39;}^a V_*(s&#39;) \\V_*(s) &amp;= \max_{a \in \mathcal{A}} \big( R(s, a) + \gamma \sum_{s&#39; \in \mathcal{S}} P_{ss&#39;}^a V_*(s&#39;) \big) \\Q_*(s, a) &amp;= R(s, a) + \gamma \sum_{s&#39; \in \mathcal{S}} P_{ss&#39;}^a \max_{a&#39; \in \mathcal{A}} Q_*(s&#39;, a&#39;)\end{aligned}\]</span></p><figure><img src="/2020/01/28/RL1/v2-604dcc4d56bfdfe410886f99520a5bdb_hd.jpg" alt="DP"><figcaption>DP</figcaption></figure><p>假设如上图，我们对所处的环境门儿清，明确的知道任意状态下行动的回报时，这就成了一个DP问题，套贝尔曼方程，求<span class="math inline">\(V_*(s)\)</span>就好了。但这么理想但并不是今天讨论的重点，我们知道在真实环境下，对客观世界是永远不可能建立那么理想的状态转移图，只能是在一次次的观测与重复中“揣测”真实世界，甚至连所有行动的reward也是我们自行评估的，而这就需要强化学习登场了。</p><h3 id="蒙特卡洛方法">蒙特卡洛方法</h3><p>是在前段时间的seqGAN第一次接触到MC-method，当时感觉蛮高级的，也没有深入去了解。但就现在大致了解的MC，感觉其实就是是统计学游戏。无异于通过无数次的盲人摸象，关于MCMC，以后会深入的学习。</p><h2 id="从一根杠杆开始">从一根杠杆开始</h2><p>google不愧人类之光(暴论)！openAI的gym库里面提供了很多的虚拟环境，用于强化学习的训练和开发，而<a href="http://gym.openai.com/docs/" target="_blank" rel="noopener">CartPole</a>绝对可说是RL界的HelloWorld。它的规则很简单，在一个存在重力的环境下，智能体（agent）在每一时刻做出左移或者右移的action，保持杠杆倾斜不超过15度。我们的目标是让杠杆存活尽可能长的时间。</p><h3 id="policy-gradient">Policy Gradient</h3><h4 id="abstract">Abstract</h4><p>强化学习旨在帮助我们找到能获得最大回报的策略，而作为强化学习的一种重要方法，policy gradient直接对策略进行建模与优化，它的reward function被定义为 <span class="math display">\[J(\theta)= \sum_{s \in \mathcal{S}} d^\pi(s) V^\pi(s)= \sum_{s \in \mathcal{S}} d^\pi(s) \sum_{a \in \mathcal{A}} \pi_\theta(a \vert s) Q^\pi(s, a)\]</span></p><p>好吧我承认，上面的话主要的目的在于提升本文逼格，对初学者理解policy gradient并没有太大帮助，下面我来试着用自己的理解来谈谈policy gradient</p><h4 id="我来给翻译翻译">我来给翻译翻译</h4><p>在传统的监督学习中，假使我们有足够多且理想的“正确答案”作为label，那么直接将交叉熵的结果进行反传，就可以拟合出足够好的模型。但在很多决策问题上，我们根本无法得到什么有效的label，就像在CartPole游戏中，我们的训练是没有任何数据集作为参考的。</p><p>其实可以把这类把任务看成像一站到底一样的知识竞赛，答错一定数量的题目即算出局。在我看来，传统的的监督学习就是搜集能到所有有题库和答案的选手，他们可以一遍一遍的背题库，最后的无限接近全对。而policy gradient下的的选手则是一次又一次的参加竞赛，没有答案可供参考，游戏结束后他获得的唯一信息也只是知道自己活了多少轮。</p><p>现在我们再回头，看看开头的的式子，似乎也就有了头绪，正如齐名，policy gradient就是对全局的policy进行建模与优化，具体在CartPole游戏里，它也是在一局游戏结束，才进行一次“复盘”，而它的目标函数也是由两部分相乘得到，第一部分是最大似然的交叉熵，第二部分是一局中所有时刻的Return。</p><p>对于第一部分，我们自不会陌生，它评估的是在特定state下，随机变量<span class="math inline">\(\pi(s)\)</span>和实际action的偏差程度，在这里体现的就是模型对自己选择的确信程度，在只考虑这部分目标函数的情况下，优化目标函数，即是提供了一个正反馈，这个模型越来越相信自己在最初状态随机作出的决策（这里说的不是很严谨，只是我自己的理解），越来越“刚愎自用”，这自然是不行的。</p><p>这里就需要引入Return了，在我看来，它相当于在复盘时给每步action打分，它相当于告诉了模型，，到底有多少可取的部分。</p><p>根据有针对性的reward进行反传，很快就可以拟合出不错的策略。听起来很理想，但这就引出了下一个问题，也就是policy gradient的核心，到底如何得到reward？</p><p>还是以CartPole为例，至少在在<code>CartPoleV1</code>这个环境里，对于单步reward的定义非常简单，游戏中agent每次action的reward都是1，听起来这个单步的reward的定义好像十分草率。不过也是十分巧妙的，我们再回想</p><h4 id="babymath可跳过">babyMath（可跳过）</h4><p>接下来，我们来推导一下policy gradient目标函数的梯度，会有一些babyMath，不过也只是符号比较唬人，并没有劝退部分（确信），当然也可以跳过或者直接去看<a href="https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html" target="_blank" rel="noopener">原文</a></p><p>现在，我们重新捡回reward function那个让人嫌弃的定义式，好好看看这个定义式是怎么来的，</p><p><span class="math display">\[J(\theta)= \sum_{s \in \mathcal{S}} d^\pi(s) V^\pi(s)= \sum_{s \in \mathcal{S}} d^\pi(s) \sum_{a \in \mathcal{A}} \pi_\theta(a \vert s) Q^\pi(s, a)\]</span></p><p><span class="math display">\[\begin{aligned}\nabla_\theta J(\theta)&amp;= \nabla_\theta \sum_{s \in \mathcal{S}} d^\pi(s) \sum_{a \in \mathcal{A}} Q^\pi(s, a) \pi_\theta(a \vert s) \\&amp;\propto \sum_{s \in \mathcal{S}} d^\pi(s) \sum_{a \in \mathcal{A}} Q^\pi(s, a) \nabla_\theta \pi_\theta(a \vert s)\end{aligned}\]</span></p><p>我们知道，在游戏的每一时刻，我们都有状态<span class="math inline">\(s_t\)</span>,此时的reward function即为<span class="math inline">\(V^\pi(s_t)\)</span>，,现在我们开始对<span class="math inline">\(\nabla_\theta V^\pi(s)\)</span>进行变换,接下来是喜闻乐见的微分环节 <span class="math display">\[\begin{aligned}&amp; \nabla_\theta V^\pi(s) \\=&amp; \nabla_\theta \Big(\sum_{a \in \mathcal{A}} \pi_\theta(a \vert s)Q^\pi(s, a) \Big) &amp; \scriptstyle{\text{根据全概率公式}}\\=&amp; \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \color{red}{\nabla_\theta Q^\pi(s, a)} \Big) &amp; \scriptstyle{\text{乘法法则}} \\=&amp; \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \color{red}{\nabla_\theta \sum_{s&#39;, r} P(s&#39;,r \vert s,a)(r + V^\pi(s&#39;))} \Big) &amp; \scriptstyle{\text{; Extend } Q^\pi \text{ with future state value.}} \\=&amp; \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \color{red}{\sum_{s&#39;, r} P(s&#39;,r \vert s,a) \nabla_\theta V^\pi(s&#39;)} \Big) &amp; \scriptstyle{P(s&#39;,r \vert s,a) \text{ or } r \text{ is not a func of }\theta}\\=&amp; \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \color{red}{\sum_{s&#39;} P(s&#39; \vert s,a) \nabla_\theta V^\pi(s&#39;)} \Big) &amp; \scriptstyle{\text{; Because }  P(s&#39; \vert s, a) = \sum_r P(s&#39;, r \vert s, a)}\end{aligned}\]</span> 从红色部分可以看出，上式是个套娃 为了理解reward，需要理解agent的状态转移。 <span class="math display">\[s \xrightarrow[]{a \sim \pi_\theta(.\vert s)} s&#39; \xrightarrow[]{a \sim \pi_\theta(.\vert s&#39;)} s&#39;&#39; \xrightarrow[]{a \sim \pi_\theta(.\vert s&#39;&#39;)} \dots\]</span></p><p>假设一局游戏可以抽象化为agent采取<span class="math inline">\(\pi_\theta\)</span>，经过<span class="math inline">\(k\)</span>步，从状态<span class="math inline">\(s\)</span>转移到状态<span class="math inline">\(x\)</span>,计作<span class="math inline">\(\rho^\pi(s \to x, k)\)</span></p><p><span class="math display">\[\rho^\pi(s \to x, k+1) = \sum_{s&#39;} \rho^\pi(s \to s&#39;, k) \rho^\pi(s&#39; \to x, 1)\]</span></p><ul><li><span class="math inline">\(k=0\)</span>时，相当于agent什么都没做，自然有：<span class="math inline">\(\rho^\pi(s \to s, k=0) = 1\)</span></li><li><span class="math inline">\(k=1\)</span>时，根据贝叶斯公式：<span class="math inline">\(\rho^\pi(s \to s&#39;, k=1) = \sum_a \pi_\theta(a \vert s) P(s&#39; \vert s, a)\)</span></li><li>推广到普遍情况，套娃出现了：<span class="math inline">\(\rho^\pi(s \to x, k+1) = \sum_{s&#39;} \rho^\pi(s \to s&#39;, k) \rho^\pi(s&#39; \to x, 1)\)</span></li></ul><p>现在我们记<span class="math inline">\(\phi(s) = \sum_{a \in \mathcal{A}} \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a)\)</span> 继续化简<span class="math inline">\(\nabla_\theta V^\pi(s)\)</span> <span class="math display">\[\begin{aligned}=&amp; \phi(s) + \sum_a \pi_\theta(a \vert s) \sum_{s&#39;} P(s&#39; \vert s,a) \color{red}{\nabla_\theta V^\pi(s&#39;)}\\=&amp; \phi(s) + \sum_{s&#39;} \sum_a \pi_\theta(a \vert s) P(s&#39; \vert s,a) \color{red}{\nabla_\theta V^\pi(s&#39;)} \\=&amp; \phi(s) + \sum_{s&#39;} \rho^\pi(s \to s&#39;, 1) \color{red}{\nabla_\theta V^\pi(s&#39;)} \\=&amp; \phi(s) + \sum_{s&#39;} \rho^\pi(s \to s&#39;, 1) \color{red}{[ \phi(s&#39;) + \sum_{s&#39;&#39;} \rho^\pi(s&#39; \to s&#39;&#39;, 1) \nabla_\theta V^\pi(s&#39;&#39;)]} \\=&amp; \phi(s) + \sum_{s&#39;} \rho^\pi(s \to s&#39;, 1) \phi(s&#39;) + \sum_{s&#39;&#39;} \rho^\pi(s \to s&#39;&#39;, 2)\color{red}{\nabla_\theta V^\pi(s&#39;&#39;)} \scriptstyle{\text{ ; Consider }s&#39;\text{ as the middle point for }s \to s&#39;&#39;}\\=&amp; \sum_{x\in\mathcal{S}}\sum_{k=0}^\infty \rho^\pi(s \to x, k) \phi(x)\end{aligned}\]</span></p><p>这样我们就得到了<span class="math inline">\(\nabla_\theta V^\pi(s)\)</span> <span class="math display">\[\begin{aligned}\nabla_\theta J(\theta)&amp;= \nabla_\theta V^\pi(s_0) &amp; \scriptstyle{\text{; Starting from a random state } s_0} \\&amp;= \sum_{s}\color{blue}{\sum_{k=0}^\infty \rho^\pi(s_0 \to s, k)} \phi(s) &amp;\scriptstyle{\text{; Let }\color{blue}{\eta(s) = \sum_{k=0}^\infty \rho^\pi(s_0 \to s, k)}} \\&amp;= \sum_{s}\eta(s) \phi(s) &amp; \\&amp;= \Big( {\sum_s \eta(s)} \Big)\sum_{s}\frac{\eta(s)}{\sum_s \eta(s)} \phi(s) &amp; \scriptstyle{\text{;  } \eta(s), s\in\mathcal{S} \text{ to be a probability distribution.}}\\&amp;= \sum_s d^\pi(s) \sum_a \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a)&amp; \scriptstyle{d^\pi(s) = \frac{\eta(s)}{\sum_s \eta(s)}\text{ is stationary distribution.}}\\&amp;= \sum_{s \in \mathcal{S}} d^\pi(s) \sum_{a \in \mathcal{A}} \pi_\theta(a \vert s) Q^\pi(s, a) \frac{\nabla_\theta \pi_\theta(a \vert s)}{\pi_\theta(a \vert s)} &amp;\\&amp;= \mathbb{E}_\pi [Q^\pi(s, a) \nabla_\theta \ln \pi_\theta(a \vert s)] &amp; \scriptstyle{\text{; Because } (\ln x)&#39; = 1/x}\end{aligned}\]</span></p><p>现在我们就得到了目标函数的梯度，它与所处的特定状态<span class="math inline">\(s\)</span>无关</p><p><span class="math display">\[\nabla_\theta J(\theta)  = \mathbb{E}_\pi [Q^\pi(s, a) \nabla_\theta \ln \pi_\theta(a \vert s)]\]</span></p><p>当然了，对应，它也有很多种变体，如下图所示</p><figure><img src="/2020/01/28/RL1/general_form_policy_gradient.png" alt="mathods"><figcaption>mathods</figcaption></figure><h3 id="code">Code</h3><p>前边水了这么多，可能还是有些云里雾里，想要直观的理解，还是得上代码</p><h4 id="g_t"><span class="math inline">\(G_t\)</span></h4><p>获得<span class="math inline">\(\nabla_\theta V^\pi(s)\)</span>并归一化</p><p>这里采取了蒙特卡洛方法来计算reward</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_discount_and_norm_reward</span><span class="params">(self)</span>:</span> <span class="comment"># reward decay and normalize</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    discount_ep_rs = np.zeros_like(self.ep_rs)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    running_add = <span class="number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(<span class="number">0</span>, len(self.ep_rs))):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">        running_add = running_add * self.gamma + self.ep_rs[t]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">        <span class="comment">#蒙特卡洛方法</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">        discount_ep_rs[t] = running_add</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># normalize episode rewards</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    discount_ep_rs -= np.mean(discount_ep_rs)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    discount_ep_rs /= np.std(discount_ep_rs)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">return</span> discount_ep_rs</span></pre></td></tr></table></figure><h4 id="object-function">Object Function</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">self.all_act_prob = tf.nn.softmax(all_act, name=<span class="string">'act_prob'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># to maximize total reward log p * R = minimize - log_p *R</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">    neg_log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=all_act, labels=self.tf_acts)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    self.loss = tf.reduce_mean((neg_log_prob * self.tf_vt))</span></pre></td></tr></table></figure><h3 id="reference">Reference</h3><p><a href="https://zhuanlan.zhihu.com/p/25498081" target="_blank" rel="noopener">强化学习入门 第一讲 MDP</a></p><p><a href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/4-4-gym/" target="_blank" rel="noopener">OpenAI gym 环境库 by莫烦</a></p><p><a href="https://tobiaslee.top/2018/03/06/Reinforcement-Learning1/" target="_blank" rel="noopener">Policy Graident 从数学到实现</a></p><p><a href="https://zhuanlan.zhihu.com/p/25743759" target="_blank" rel="noopener">强化学习之蒙特卡罗方法</a></p><p><a href="http://www.foolweel.com/2019/05/02/rl-basic/" target="_blank" rel="noopener">强化学习概述</a></p><p><a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html#key-concepts" target="_blank" rel="noopener">A (Long) Peek into Reinforcement Learning</a></p><p><a href="https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html" target="_blank" rel="noopener">Policy Gradient Algorithms</a></p><p><a href="https://jeremykun.com/2015/04/06/markov-chain-monte-carlo-without-all-the-bullshit/" target="_blank" rel="noopener">Markov Chain Monte Carlo Without all the Bullshit</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一段时间开始seqGAN第一次接触到RL，正好寒假时间富裕，补一些强化学习的基础&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="RL" scheme="http://freemty.github.io/tags/RL/"/>
    
  </entry>
  
  <entry>
    <title>谈谈我们的“异化”</title>
    <link href="http://freemty.github.io/2019/12/05/suibi1/"/>
    <id>http://freemty.github.io/2019/12/05/suibi1/</id>
    <published>2019-12-05T15:33:24.000Z</published>
    <updated>2020-02-18T19:47:37.705Z</updated>
    
    <content type="html"><![CDATA[<p>  些这篇文章的是前段时间的毛概大作业，虽然不长，但也费了不少心力。不得不说，写作过程还是相当痛苦的，不过也难得可以以这种自己“瞧得起”的方式表达真情实感。所以发在博客上，希望以后可以继续写作这个好习惯吧。</p><a id="more"></a><h3 id="这个时代的异化">这个时代的异化</h3><p>  异化，代表着人对自己的劳动与外部世界丧失控制，甚至反被操纵的过程，在马克思的笔下，它是“人的受难”，而在现今的网络空间中，我们的情绪与表达也在越来越多的呈现着这样的异化。</p><h4 id="清醒的哲人王们">清醒的“哲人王”们</h4><p>  格雷塔·桑伯格，瑞典的环保少女，因她极端反现代化的环保诉求与乖张的事迹而为人所知。2018年，15岁的她每个周五都会独自在瑞典国会前举着“为气候变化而罢课”抗议静坐。并参加了今年九月的联合国气候峰会，并因演讲中那张表情夸张的“How Dear You”而红遍中国的社交网络(这里的“红”纯粹是指其激发的情绪之剧烈)。活脱一个完美的“妄人”范式。与“疯姑娘”一同被推到风口的是，是“普京一语戳破西方环保阴谋”，“中国的绿化成就震撼世界，为英雄们点赞”。。。 「说来戏谑，每当我们被西方白左气到时，总是要抬出那些“最可爱的人们”给我们撑腰」</p><p>  说老实话，让我们用自己的直觉判断，也大概可以明白这位“疯姑娘”的诉求并不现实，许多乖张的事迹也确实逃不开炒作的嫌疑。可“不实际”，“不纯粹”难道就真的能作为我们情绪如此高亢的理由吗?如果“非蠢即坏”的咒骂真的源于我们的道德自觉，那么在网络上，我们对大屠杀，纳粹，红色高棉，又何曾有过如此纯粹的愤怒呢? 「主观的认为，在当今的网络中不管是大屠杀的恶，还是雷锋式的善都沦为了虚无的，关于善恶的“道理”;而网络中的高亢表达，根本上源于一种“恶感”」</p><p>  在这里，人人都是了不起的智者，一眼就戳穿了反智的本质与西方的阴谋，用尽工整精致的语言，向人们证明着“我什么都不做”比“反智”高明多了，再顺带对那些真正真诚的实践者施以崇高的敬意。熟练的运用着自己的理性，歌颂着“伟大”，唾弃着“虚伪”，何其高明的“哲人王”们!</p><p>  如果我说这么多只是为了讽刺所谓“乌合之众”，那就太过流于表面了，我想问的是，我们的愤怒与崇敬，是不是都有些太过轻巧了?在我看来这不仅仅是对于“妄人”的讽刺，更是对于“偶像”的羞辱。试问诸位，既然你们对那些投身环保的实践者们如此崇敬，请问，你们能拿出那位“疯姑娘”十分之一的热忱去做过哪怕一次你们认为“不虚伪”“有意义”的环保?我倒不妨直接说开了吧，你们口中的“崇高”“务实”的英雄们，不过是你们拿来搬弄是非的工具罢了。我们都特别明白行动和言辞的界限，从不轻易僭越到无能为力的境地。</p><pre><code>叶公子高好龙，钩以写龙，凿以写龙，屋室雕文以写龙。于是天龙闻而下之，叶公见之，弃而还走，失其魂魄，五色无主。是叶公非好龙也，好夫似龙而非龙者也。</code></pre><p>  在我看来，这种过分“冷静”的情绪实际上源于一种实践的不可欲，现代社会无限体量与联通，让价值的丧失成了一种必然代价，在我们父辈或更早的时候，一个人在其所在的宗族国企大院这样的共同体中，你只需要在这个共同体或者大院里做到有一技以傍身，你就能获得充分的”价值感”，而在当今这个“无限”世界中的，你所做的一切，只要打开网络，看到那些“神迹”，作为一个孤立的个体，还怎能真正的相信自己实践的价值「可能表达的有些极端，但确实有这样的倾向」。于是，在人们的言论与想象之中，个体的能量只剩零和无穷大，除非您能绝圣弃智，行出“神迹”，任我们顶礼膜拜。不然就请闭嘴。什么，你告诉我这也叫成就?五十步笑百步罢了，指不定背后还有什么不可告人的阴谋!「或许是一种语言的遮蔽，在实践的层面上，“五十步”怎么就不能“笑百步”了?」</p><p>  从人格上讲，“妄人”“英雄”于我们同样遥远。可我们羞于面对这种平庸，痛恨一切不能一蹴而就的改变，我们只能指望着几句精致的讽刺与假惺惺的热爱，证明自己真的与英雄们“心有戚戚焉”，对着光屏艰难着维护者一个“自洽”的我。激昂的言辞昭示的是无根之人的惶恐。以及对于独自实践的恐惧。</p><h4 id="庶民的胜利">庶民的胜利</h4><p>  今年七月后，一个不那么善意的称呼出现在了网络上--“废青”，意指那些在香港“反送中”运动中参与“暴乱”的香港年轻人。而这个称呼也是用来讽刺他们在“自以为正确”的“暴乱”中诸多幼稚与滑稽的行为。</p><p>  由于可能涉及一些政治敏感话题，我觉得在这里有必要申明一下，现在社会上所有发生的事，在网络这个“拟像”上激起的涟漪，从来都与事实真相无关。网络中普遍存在的“表达异化”，都是蕴藏在浪潮中不断共振的情绪而非事实的道理之中。因此我无意对所提及的事件做任何事实层面的判断，我所在乎的是“第四面墙”后观众席上的声音。在撇清责任后，让我们再次回到这场“时代革命”的浪潮中。从七月中旬，无数的浪潮一波又一波的掀起，“帝吧百万出征”“阿中女孩为国护旗”。。。无数年轻人用着自己的方式“捍卫”着的价值。</p><p>  在这次“全民爱国”的主阵地之一，新浪微博的“#中国”超话下，鲁迅五四时期《新青年》上的一段文章</p><pre><code>愿中国青年都摆脱冷气，只是向上走，不必听自暴自弃者流的话。能做事的做事，能发声的发声。有一分热，发一分光。就令萤火一般，也可以在黑暗里发一点光，不必等候炬火。此后如竟没有炬火，我便是唯一的光。</code></pre><p>再次被广泛的引用转发，初听起来极富感情，仔细一想，越觉得不对。难道，这些在网路上“为国护旗，挺港警”的青年们，真的把自己带入到了那些五四学生的视角了吗?</p><p>  在过去那些风云激荡的年代，我们抗议，写作,斗争，用着自己的热血与理想，表达着自己真实的诉求。同样，这一切“真”的行动，从来都意味着困难，风险，与代价。(我没有任何号召大家去模仿的意思，只是想说，真正的表达与捍卫，从来都是伴着付出与冒险的)</p><p>  而时至今日，我不妨直说，在这场斗宏大运动中的每个青年，他们都心知肚明，自己胜券在握，他们不论说出如何过激的言语，都不用承担任何真实的代价，不论是武力的对抗还是舆论的斗争，“阿中”的胜利都只是时间问题。他们在这场根本不会波及自己真实生活的战场上肆意“杀敌”。</p><p>  他们的慷慨陈词，与其说实在发自内心的捍卫立场，不如说是在胜券在握的的关头，毫无风险，毫无代价的享受着胜利的喜悦!如果说那些不辨菽麦走上街头的勇武派是“废青”，那么在网路上嗜胜的青年们，绝对是“强青”了!换一种极端的讲法，与其说他们是爱国，爱某些价值，不如说他们是爱“赢”罢了。</p><p>  热血方刚的青年们，享受着毫无代价，毫无风险的“勇气”与“热情”，所带来的快感。可这终归是“假勇气”，“假热情”。我想问，在洞穴中沉溺于烛光倒影的囚徒们的，就算解开镣铐，还有没有胆量去直面阳光与这真实的世界呢?</p><h4 id="代庖之乐">“代庖”之乐</h4><p>  如果说这些“假捍卫”“假勇气”的只是一种不自知的异化，那这场浪潮中的另一幅面向，则呈现出来一种更深的异化与懦弱。</p><p>  大概是八月中旬一组“深圳警方千人实战演习”的短视频刷爆了网络，最令我惊讶的是在评论中多数都是类似“年度大戏，即将上演”，“结局到来，敬请期待!”这类具有“幽默”与期待的讽刺。(毫无疑问大家都明白着这隐喻着什么)如果说帝吧出征与香港青年对骂还是算是自发行动去捍卫自己的立场的一场自维的“战斗”，那大家对“深圳警方演习”“驻港部队换防”这样的拍手称快，则纯粹是一种对于“代庖”的享受，我甚至可以极为武断的说，如果这些表述中有一个主导的情绪，那一定是“胜利的喜悦”。 「这样糟糕的情绪，自然与不断的对立与极端化报道脱不开干系，青年们想象中的敌人让早已非人化，不过可悲的这已不是什么新鲜事了」</p><p>  伴随这种“代庖”，还有一个更糟糕的面向，那就是在网络各种场合“举报”这种表达形式的蔚然成风。在微博上许多明星的“反黑组”「意指粉丝中为了维护明星声誉而在网络上巡查监控负面言论的自组织形式」，每天都会定时贴出数十甚至上百的账号信息，用以让粉丝团体精确举报，通过官方封号来消除负面评价。可见我们对于这种“高效”的斗争形式适应的相当之快。</p><p>  可以说，这种在网络世界上对于“代庖”的渴望，是我们面对如此庞大的现代社会与国家机器时，最舒适的获得“自洽”的方式。可是，“代庖”从来不是没有代价的，他的代价，就是纯粹的交托，纯粹的异化，放弃一切应然的执念，相信自己外部的一切都是“State of The Art”(当前最好的结果)。才能心安理得。</p><p>  最后我只想说，这种享受“代庖”的狂欢，已不仅仅是的异化表达，而是这个庞大现代社会所异化的虚弱之人唯一的表达罢了!</p><h3 id="写在最后">写在最后</h3><p>  其实每当有这样“文以载道”的机会，我都会燃起不小的热情，想去说点什么，可当我真正的拿起笔，很多原来引以为傲的“灼见”，落到纸上，都只剩一些搬弄是非的文字游戏，读完尽是些言之无物的空谈。这种挫败也带给了我一个新的视角，是不是在网络时代，我们的“言之无物”成为了一种必然。面对那么多富有煽动力的媒介内容源源不断的涌来，我们的观点变得毫无意义，我们只能说“好”与“坏”，或是运用“精致的文字游戏”去捍卫别人预设好的立场。</p><p>  经历了一天极为痛苦的写作，也让我意识到了，写作是一个内在蕴含反思的过程，真正落到纸上的文字，才是经得起反思，蕴含着真实表达的。所以最后我想说，对这种表达的异化。我们并不是完全无力的，但终是要付出一些困难的。要摒弃这种异化，就要让我们的表达不再是，“搬弄是非”，承载着“假勇气”的“文字游戏”，少争吵，多写作。</p><p>  文章不长，描述很多的现象其实也充满了我主观的臆想，不过我坚信，在这个“人人都是知识分子”的时代，真的情感远比精致的道理来的可贵，一如深刻的视角比最后真相更能让人反思，指引我们去真正的实践!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  些这篇文章的是前段时间的毛概大作业，虽然不长，但也费了不少心力。不得不说，写作过程还是相当痛苦的，不过也难得可以以这种自己“瞧得起”的方式表达真情实感。所以发在博客上，希望以后可以继续写作这个好习惯吧。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="随笔" scheme="http://freemty.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>「Paper-Reading」AlphaGo + AlphaGoZero</title>
    <link href="http://freemty.github.io/2019/11/30/AlphaGo/"/>
    <id>http://freemty.github.io/2019/11/30/AlphaGo/</id>
    <published>2019-11-30T15:29:35.000Z</published>
    <updated>2022-02-11T12:51:05.413Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
      <category term="RL" scheme="http://freemty.github.io/tags/RL/"/>
    
      <category term="paper reading" scheme="http://freemty.github.io/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>「Paper-Reading」Autoencoder as Assistant Supervisor Improving Text Representation for Chinese Social Media Text Summarization</title>
    <link href="http://freemty.github.io/2019/11/30/superAE/"/>
    <id>http://freemty.github.io/2019/11/30/superAE/</id>
    <published>2019-11-30T15:29:35.000Z</published>
    <updated>2020-02-27T10:36:24.980Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1805.04869v1.pdf" target="_blank" rel="noopener">原文链接</a></p><h3 id="abstrct">Abstrct</h3><p>现今主流的摘要生成都是基于seq2seq,但事实上用于训练的文本大都过于冗杂(即使LCSTS也存在这个问题)导致在在encode时很难真正的“习得”语义(semantic)而reference summary大都短且语义明确。文中提出的模型「SuperAE」正是利用了这一点,在encode时引入了用于监督的Autocoder取得了,很好的结果</p><a id="more"></a><h3 id="introduction">Introduction</h3><p>由于RNN结构的特性,不管作何变种和优化(LSTM&amp;GRU)都难以避免梯度爆炸和消失,因此可以说编码长文本时语义的遗失是一种必然.而对于短文本的编码则可以很好的理解语义.根据这个思路,可以在编码时增加对summary的编码,用它来监督encoder对原文的的&quot;理解&quot;情况</p><h3 id="proposed-model">Proposed Model</h3><h4 id="supervision-with-autoencoder">Supervision with Autoencoder</h4><p>传统的seq2seq在这就不多赘述,encode层还是主流的双层LSTM,在训练时,加入了新的摘要编码器,输出为<span class="math inline">\(z_s\)</span>,引入了新的损失项(<span class="math inline">\(\lambda\)</span>有经验值0.3作为初始值)</p><p>$ L_s =d(z_t,z_s) $</p><p>其中</p><p>$ d(z_t,z_s) = ||z_t - z_s||_{2} $</p><p>显而易见此监督(supervisor)项用以描述二者输出的相似度。按我从直觉上的理解,监督项,可以很好的防止模型不被比较晦涩或者说质量较差的摘要样例带偏</p><p><img src="/2019/11/30/superAE/ae_graph.png"></p><h4 id="adversarial-learning">Adversarial Learning</h4><p>上一节添加了用于监督的新损失项,因此就存在了新的超参数<span class="math inline">\(\lambda\)</span>用来控制监督的力度.显而易见,训练时,如果摘要和原文的语义相关性很高，那么监督的力度应该较高,反之,如果摘要太草了(QAQ).就应该适当降低监督的惩罚力度　因此，如果训练时的惩罚力度是动态的，训练的效果当然会更好。所以我们需要一种技巧来判别这组文本和摘要的相关性，是否需要“加大力度”</p><p>到这里,就该对抗学习(adversarial learning)出场了.本文先验的把seq2seq里的输出看作虚假表示(&quot;fake&quot;representation),autoencoder的输出看作标准表示(&quot;gold&quot;representation) 对此,在训练中引入了discriminator(判别器?歧视器?)用来分辨输出到底是&quot;gold&quot;还是&quot;fake&quot;</p><p>从数学上理解，这是判别器的目标函数</p><p>$ L_D(<em>D) = -logP</em>{<em>D}(y =1|z_t)-logP</em>{_D}(y = 0|z_s) $</p><p>这是监督学习的目标函数</p><p>$ L_G(<em>E) = -logP</em>{<em>D}(y =0|z_t)-logP</em>{_D}(y = 1|z_s) $</p><p>从直觉上理解,监督学习有着使两编码器的输出语义无限接近的动机,而判别器有尽力分别二者的动机,二者都存于损失函数中,如果辨别器可以区分二者<span class="math inline">\(\lambda\)</span>减小,减轻监督力度,反之<span class="math inline">\(\lambda\)</span>增加,加大力度</p><p>这里看的有点迷，把原文po上来吧</p><blockquote><p>the supervision, which minimizes the dis-tance of the representations and makes them sim-ilar, tries to prevent the discriminator from mak-ing correct predictions.</p></blockquote><h3 id="loss-function-and-training">Loss Function and Training</h3><p>loss-function共由三部分组成,第一部分是原本seq2seq decoder和autoencoder均经过decod后输出的交叉熵的和,第二部分是上文第一节监督项的损失,第三部分是上文第二节判别器的损失</p><p>$ L_1 = L_{seq2seq} + L_{AE} + L_s + L_D + L_G $</p><p>[result](result.png）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1805.04869v1.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;abstrct&quot;&gt;Abstrct&lt;/h3&gt;
&lt;p&gt;现今主流的摘要生成都是基于seq2seq,但事实上用于训练的文本大都过于冗杂(即使LCSTS也存在这个问题)导致在在encode时很难真正的“习得”语义(semantic)而reference summary大都短且语义明确。文中提出的模型「SuperAE」正是利用了这一点,在encode时引入了用于监督的Autocoder取得了,很好的结果&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="NLP" scheme="http://freemty.github.io/tags/NLP/"/>
    
      <category term="paper reading" scheme="http://freemty.github.io/tags/paper-reading/"/>
    
  </entry>
  
</feed>
